{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Iqce6K5fHTh26WYIWDanu9x83ofbFT97","authorship_tag":"ABX9TyNzHbp3GR4rtN7x0qblwNH/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"ze7LsPkoDMZ2","executionInfo":{"status":"ok","timestamp":1714089761448,"user_tz":-120,"elapsed":1301,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision\n","import matplotlib.pyplot as plt\n","import torch._dynamo\n","from collections import defaultdict\n","from functools import reduce\n","from PIL import Image\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["def load_adam_image(df, idx, root='./drive/MyDrive/colab/datasets/ADAM/Training1200'):\n","\timage_name = df.loc[idx, 'imgName']\n","\tdata_type = 'AMD' if image_name.startswith('A') else 'Non-AMD'\n","\timage_path = f'{root}/{data_type}/{image_name}'\n","\timage = Image.open(image_path)\n","\tbbox = (df.loc[idx, 'Fovea_X'], df.loc[idx, 'Fovea_Y'])\n","\treturn image, bbox\n","\n","\n","def build_adam_dataset(df, image_size=256):\n","  imgs, bboxes = [], []\n","\n","  for idx in df.index:\n","    img, bbox = load_adam_image(df, idx)\n","\n","    img_arr = np.array(img).transpose((2,0,1)).astype(np.float32) / 255 # uint8::max\n","    imgs.append(img_arr)\n","\n","    bbox_arr = np.array(bbox).astype(np.float32) / image_size\n","    bboxes.append(bbox_arr)\n","\n","  imgs = map(lambda x: torch.tensor(x, dtype=torch.float32), imgs)\n","  bboxes = map(lambda x: torch.tensor(x, dtype=torch.float32), bboxes)\n","\n","  return [(i, b) for i, b in zip(imgs, bboxes)]\n","\n","\n","def get_adam_loaders_from_memory(batch_size, test_batch_size=None, cutoff=1, root='../../datasets/ADAM/Training1200'):\n","\tif test_batch_size is None: test_batch_size = batch_size * 2\n","\n","\tfovea_df = pd.read_csv(f'{root}/fovea_location.csv').drop(['ID'], axis=1)\n","\ttrain_df, test_df = train_test_split(fovea_df, test_size=1-cutoff, shuffle=True)\n","\n","\ttrain_ds = build_adam_dataset(train_df)\n","\ttest_ds = build_adam_dataset(test_df)\n","\n","\ttrain_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n","\ttest_dl = torch.utils.data.DataLoader(test_ds, batch_size=test_batch_size, shuffle=False, num_workers=2)\n","\n","\treturn train_dl, test_dl\n","\n","\n","class ResBlock(nn.Module):\n","  def __init__(self, in_channels, out_channels):\n","    super().__init__()\n","    self.base1 = nn.Sequential(\n","      nn.Conv2d(in_channels, in_channels, kernel_size=3, padding='same'),\n","      nn.BatchNorm2d(in_channels),\n","      nn.ReLU(True)\n","    )\n","    self.base2 = nn.Sequential(\n","      nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n","      nn.BatchNorm2d(out_channels),\n","      nn.ReLU(True)\n","    )\n","    self.mpool = nn.MaxPool2d(2)\n","\n","  def forward(self, x):\n","    x = self.base1(x) + x\n","    x = self.base2(x)\n","    x = self.mpool(x)\n","    return x\n","\n","\n","class SODNet(nn.Module):\n","  def __init__(self, in_channels, first_output_channels):\n","    super().__init__()\n","    self.main = nn.Sequential(\n","      ResBlock(in_channels, first_output_channels),\n","      ResBlock(first_output_channels, 2 * first_output_channels),\n","      ResBlock(2 * first_output_channels, 4 * first_output_channels),\n","      ResBlock(4 * first_output_channels, 8 * first_output_channels),\n","\n","      nn.Conv2d(8 * first_output_channels, 16 * first_output_channels, kernel_size=3),\n","      nn.MaxPool2d(2),\n","      nn.Flatten(),\n","      nn.Linear(7 * 7 * 16 * first_output_channels, 2)\n","    )\n","\n","  def forward(self, x):\n","    return self.main(x)\n","\n","\n","def fit_sodnet_step(model, image_batch, bbox_batch, loss_func, optimizer):\n","  optimizer.zero_grad()\n","  output = model(image_batch)\n","  loss = loss_func(output, bbox_batch)\n","  loss.backward()\n","  optimizer.step()\n","  return loss.item()\n","\n","\n","def latency(model, sample):\n","\tstart = torch.cuda.Event(enable_timing=True)\n","\tend = torch.cuda.Event(enable_timing=True)\n","\tstart.record()\n","\t_ = model(sample)\n","\tend.record()\n","\ttorch.cuda.synchronize()\n","\treturn start.elapsed_time(end)"],"metadata":{"id":"K6MRRI8DFnQ_","executionInfo":{"status":"ok","timestamp":1714090380312,"user_tz":-120,"elapsed":231,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    print('device count:', torch.cuda.device_count())\n","    device = torch.device(0)\n","    device_cap = torch.cuda.get_device_capability()\n","    print(f\"GPU {torch.cuda.get_device_name(0)} available with compatibility {device_cap}\")\n","    if device_cap not in ((7, 0), (8, 0), (9, 0)):\n","        print(\"GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU unavailable\")"],"metadata":{"id":"Oxy-WPgNZzVx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714089726683,"user_tz":-120,"elapsed":6,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"0aa43eab-a117-4654-c8df-284790d646f6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["device count: 1\n","GPU Tesla T4 available with compatibility (7, 5)\n","GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"LCXO4kOPZtfk"}},{"cell_type":"code","source":["epochs = 8\n","lr = 1e-2\n","timestamp = time.time_ns()\n","results_eager_filepath = f'./drive/MyDrive/colab/results/pytorch-sodnet-eager-{timestamp}.csv'\n","results_compile_filepath = f'./drive/MyDrive/colab/results/pytorch-sodnet-compile-{timestamp}.csv'\n","start = torch.cuda.Event(enable_timing=True)\n","end = torch.cuda.Event(enable_timing=True)"],"metadata":{"id":"IqXgntJZFMBD","executionInfo":{"status":"ok","timestamp":1714089726684,"user_tz":-120,"elapsed":5,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Teaining - eager mode"],"metadata":{"id":"RydSRybjbVxx"}},{"cell_type":"code","source":["telemetry_eager = defaultdict(list)\n","\n","train_dl, test_dl = get_adam_loaders_from_memory(8, cutoff=0.8, root='./drive/MyDrive/colab/datasets/ADAM/Training1200')\n","model = SODNet(3, 16).to(device)\n","model.train()\n","loss_func = nn.SmoothL1Loss(reduction=\"sum\")\n","optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n","\n","for epoch in range(1, epochs + 1):\n","  train_loss = 0.0\n","  start.record()\n","  for image_batch, bbox_batch in train_dl:\n","    image_batch, bbox_batch = image_batch.to(device), bbox_batch.to(device)\n","    train_loss += fit_sodnet_step(model, image_batch, bbox_batch, loss_func, optimizer)\n","  end.record()\n","  torch.cuda.synchronize()\n","\n","  telemetry_eager['model_name'].append('SODNet')\n","  telemetry_eager['phase'].append('training')\n","  telemetry_eager['epoch'].append(epoch)\n","  telemetry_eager['loss'].append(train_loss / len(train_dl))\n","  telemetry_eager['performance'].append(-1)\n","  telemetry_eager['elapsed_time'].append(start.elapsed_time(end) * 1e6)\n","  pd.DataFrame(telemetry_eager).to_csv(results_eager_filepath, index=False)\n","  print(f'Epoch {epoch} finished with execution time of {start.elapsed_time(end) / 1e3}s')"],"metadata":{"id":"Qn0AYArkbhvh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714090140721,"user_tz":-120,"elapsed":374852,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"a8486469-9097-4dac-e2d6-c644cf1d657a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 finished with execution time of 6.06935498046875s\n","Epoch 2 finished with execution time of 4.29643505859375s\n","Epoch 3 finished with execution time of 4.38639599609375s\n","Epoch 4 finished with execution time of 3.825910888671875s\n","Epoch 5 finished with execution time of 4.44194091796875s\n","Epoch 6 finished with execution time of 4.41042626953125s\n","Epoch 7 finished with execution time of 3.82102197265625s\n","Epoch 8 finished with execution time of 4.23613671875s\n"]}]},{"cell_type":"markdown","source":["## Latency - both modes"],"metadata":{"id":"vMTlkrS_fY4R"}},{"cell_type":"code","source":["telemetry_compile = defaultdict(list)"],"metadata":{"id":"hW_SmXLUfdA1","executionInfo":{"status":"ok","timestamp":1714090189253,"user_tz":-120,"elapsed":3,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["warmup = 10\n","adam, _ = get_adam_loaders_from_memory(epochs + warmup + 1, cutoff=0.8, root='./drive/MyDrive/colab/datasets/ADAM/Training1200')\n","adam = next(iter(adam))[0].to(device)\n","model = SODNet(3, 16).to(device)\n","torch._dynamo.reset()\n","model_comp = torch.compile(model, mode='reduce-overhead')\n","model.eval()\n","\n","telemetry_eager_times = []\n","telemetry_compile_times = []\n","\n","# compilation\n","with torch.no_grad():\n","  e = latency(model, adam[-1].unsqueeze(0))\n","  print('compilation - eager mode:', e)\n","  telemetry_eager_times.append(e)\n","\n","  c = latency(model_comp, adam[-1].unsqueeze(0))\n","  print('compilation - compile mode:', c)\n","  telemetry_compile_times.append(c)\n","\n","  for i in range(epochs + warmup):\n","    # warmup\n","    e = latency(model, adam[i].unsqueeze(0))\n","    c = latency(model_comp, adam[i].unsqueeze(0))\n","\n","    # latency\n","    if i >= warmup:\n","        telemetry_eager_times.append(e)\n","        telemetry_compile_times.append(c)\n","\n","em = np.median(telemetry_eager_times)\n","cm = np.median(telemetry_compile_times)\n","print(f'median exec time (e/c): {em} / {cm}')\n","print(f'compiled graph is on average {em / cm} times faster than eager execution')\n","\n","\n","# telemetry\n","for telemetry, telemetry_times in [(telemetry_eager, telemetry_eager_times),\n","                                   (telemetry_compile, telemetry_compile_times)]:\n","  telemetry['model_name'].extend([\"SODNet\"] * (epochs + 1))\n","  telemetry['phase'].extend(['graph_compilation'] + ['latency'] * epochs)\n","  telemetry['epoch'].extend([1] + list(range(1, epochs + 1)))\n","  telemetry['loss'].extend([-1] * (epochs + 1))\n","  telemetry['performance'].extend([-1] * (epochs + 1))\n","  telemetry['elapsed_time'].extend(telemetry_times)\n","\n","pd.DataFrame(telemetry_compile).to_csv(results_compile_filepath, index=False)\n","pd.DataFrame(telemetry_eager).to_csv(results_eager_filepath, index=False)"],"metadata":{"id":"1yP_Joevfg6P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714090521074,"user_tz":-120,"elapsed":22097,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"589fa032-8f87-4e2e-e41e-714ce0ab6508"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["compilation - eager mode: 29.676544189453125\n","compilation - compile mode: 16316.23046875\n","median exec time (e/c): 2.8970561027526855 / 0.8697919845581055\n","compiled graph is on average 3.3307459187779522 times faster than eager execution\n"]}]},{"cell_type":"markdown","source":["## Latency on batch - both modes"],"metadata":{"id":"vC8ninD2ibed"}},{"cell_type":"code","source":["warmup = 10\n","adam, _ = get_adam_loaders_from_memory(8, cutoff=0.8, root='./drive/MyDrive/colab/datasets/ADAM/Training1200')\n","adam = iter(adam)\n","model = SODNet(3, 16).to(device)\n","torch._dynamo.reset()\n","model_comp = torch.compile(model, mode='reduce-overhead')\n","model.eval()\n","\n","telemetry_eager_times = []\n","telemetry_compile_times = []\n","\n","# compilation\n","with torch.no_grad():\n","  batch = next(adam)[0].to(device)\n","  e = latency(model, batch)\n","  print('compilation - eager mode:', e)\n","  telemetry_eager_times.append(e)\n","\n","  c = latency(model_comp, batch)\n","  print('compilation - compile mode:', c)\n","  telemetry_compile_times.append(c)\n","\n","  for i in range(epochs + warmup):\n","    batch = next(adam)[0].to(device)\n","    # warmup\n","    e = latency(model, batch)\n","    c = latency(model_comp, batch)\n","\n","    # latency\n","    if i >= warmup:\n","        telemetry_eager_times.append(e)\n","        telemetry_compile_times.append(c)\n","\n","em = np.median(telemetry_eager_times)\n","cm = np.median(telemetry_compile_times)\n","print(f'median exec time (e/c): {em} / {cm}')\n","print(f'compiled graph is on average {em / cm} times faster than eager execution')\n","\n","\n","# telemetry\n","for telemetry, telemetry_times in [(telemetry_eager, telemetry_eager_times),\n","                                   (telemetry_compile, telemetry_compile_times)]:\n","  telemetry['model_name'].extend([\"SODNet\"] * (epochs + 1))\n","  telemetry['phase'].extend(['graph_compilation_batch'] + ['latency_batch'] * epochs)\n","  telemetry['epoch'].extend([1] + list(range(1, epochs + 1)))\n","  telemetry['loss'].extend([-1] * (epochs + 1))\n","  telemetry['performance'].extend([-1] * (epochs + 1))\n","  telemetry['elapsed_time'].extend(telemetry_times)\n","\n","pd.DataFrame(telemetry_compile).to_csv(results_compile_filepath, index=False)\n","pd.DataFrame(telemetry_eager).to_csv(results_eager_filepath, index=False)"],"metadata":{"id":"BEpUTV5eigIR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714090647463,"user_tz":-120,"elapsed":13441,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"38ef49b2-e248-4e44-be96-dbd15e23aea4"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["compilation - eager mode: 8.954272270202637\n","compilation - compile mode: 7802.685546875\n","median exec time (e/c): 4.854368209838867 / 4.329376220703125\n","compiled graph is on average 1.121262732174955 times faster than eager execution\n"]}]},{"cell_type":"markdown","source":["## Training - compile mode"],"metadata":{"id":"c8Bw_P1IekZf"}},{"cell_type":"code","source":["train_dl, test_dl = get_adam_loaders_from_memory(8, cutoff=0.8, root='./drive/MyDrive/colab/datasets/ADAM/Training1200')\n","model = SODNet(3, 16).to(device)\n","torch._dynamo.reset()\n","model_comp = torch.compile(model, mode='reduce-overhead')\n","model.train()\n","loss_func = nn.SmoothL1Loss(reduction=\"sum\")\n","optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n","fit_sodnet_step_comp = torch.compile(fit_sodnet_step, mode=\"reduce-overhead\")\n","\n","for epoch in range(1, epochs + 1):\n","  train_loss = 0.0\n","  start.record()\n","  for image_batch, bbox_batch in train_dl:\n","    image_batch, bbox_batch = image_batch.to(device), bbox_batch.to(device)\n","    train_loss += fit_sodnet_step_comp(model_comp, image_batch, bbox_batch, loss_func, optimizer)\n","  end.record()\n","  torch.cuda.synchronize()\n","\n","  telemetry_compile['model_name'].append('SODNet')\n","  telemetry_compile['phase'].append('training')\n","  telemetry_compile['epoch'].append(epoch)\n","  telemetry_compile['loss'].append(train_loss / len(train_dl))\n","  telemetry_compile['performance'].append(-1)\n","  telemetry_compile['elapsed_time'].append(start.elapsed_time(end) * 1e6)\n","  pd.DataFrame(telemetry_compile).to_csv(results_compile_filepath, index=False)\n","  print(f'Epoch {epoch} finished with execution time of {start.elapsed_time(end) / 1e3}s')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PtANwdMcespZ","executionInfo":{"status":"ok","timestamp":1714091061940,"user_tz":-120,"elapsed":145285,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"2566fc6f-f434-429a-bd8f-675b0d178528"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 finished with execution time of 108.7909375s\n","Epoch 2 finished with execution time of 6.79148095703125s\n","Epoch 3 finished with execution time of 4.13099462890625s\n","Epoch 4 finished with execution time of 3.879884521484375s\n","Epoch 5 finished with execution time of 4.067753173828125s\n","Epoch 6 finished with execution time of 4.41709521484375s\n","Epoch 7 finished with execution time of 3.645645751953125s\n","Epoch 8 finished with execution time of 3.629512451171875s\n"]}]}]}