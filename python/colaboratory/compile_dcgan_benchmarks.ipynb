{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M2Recdn2KNBp","outputId":"653af1ef-220b-42db-cfa7-6a9a6a7c5c4f","executionInfo":{"status":"ok","timestamp":1736383579034,"user_tz":-60,"elapsed":60066,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%pip uninstall torch -y --quiet\n","%pip install triton==3.0.0 --quiet\n","%pip install torch==2.5.1 --quiet"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"0zi0bbEo5VB5","executionInfo":{"status":"ok","timestamp":1736383579034,"user_tz":-60,"elapsed":13,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision.models import resnet50, densenet121, mobilenet_v2, convnext_tiny\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision\n","import matplotlib.pyplot as plt\n","import torch._dynamo\n","from collections import defaultdict\n","from functools import reduce"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"XEYngN0ZggCO","executionInfo":{"status":"ok","timestamp":1736383579035,"user_tz":-60,"elapsed":13,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"outputs":[],"source":["def get_celeba_loader(batch_size, image_size=64, root='./drive/MyDrive/colab/datasets/celeba'):\n","    transform = torchvision.transforms.Compose([\n","        torchvision.transforms.Resize(image_size),\n","        torchvision.transforms.CenterCrop(image_size),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","    ])\n","\n","    ds = torchvision.datasets.ImageFolder(root=root, transform=transform)\n","    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","    return dl\n","\n","\n","def get_celeba_loader_from_memory(batch_size, image_size=64, root='./drive/MyDrive/colab/datasets/celeba'):\n","\tdl = get_celeba_loader(batch_size, image_size=image_size, root=root)\n","\tcollected_batches = [batch for batch in dl]\n","\treturn collected_batches\n","\n","\n","def fit_dcgan_step(generator, discriminator, device, real, loss_func, optimizerG, optimizerD, latent_vec_size):\n","  real_label = 1.\n","  fake_label = 0.\n","\n","  discriminator.zero_grad()\n","  b_size = real.size(0)\n","  label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","  output = discriminator(real).view(-1)\n","  errD_real = loss_func(output, label)\n","  errD_real.backward()\n","  D_x = output.mean().item()\n","\n","  noise = torch.randn(b_size, latent_vec_size, 1, 1, device=device)\n","  fake = generator(noise)\n","  label.fill_(fake_label)\n","  output = discriminator(fake.detach()).view(-1)\n","  errD_fake = loss_func(output, label)\n","  errD_fake.backward()\n","  D_G_z1 = output.mean().item()\n","  errD = errD_real + errD_fake\n","  optimizerD.step()\n","\n","  generator.zero_grad()\n","  label.fill_(real_label)\n","  output = discriminator(fake).view(-1)\n","  errG = loss_func(output, label)\n","  errG.backward()\n","  D_G_z2 = output.mean().item()\n","  optimizerG.step()\n","\n","  return [errG.item(), errD.item(), D_x, D_G_z1, D_G_z2]\n","\n","\n","def dcgan_weights_init(model):\n","  classname = model.__class__.__name__\n","  if classname.find('Conv') != -1:\n","      nn.init.normal_(model.weight.data, 0.0, 0.02)\n","  elif classname.find('BatchNorm') != -1:\n","      nn.init.normal_(model.weight.data, 1.0, 0.02)\n","      nn.init.constant_(model.bias.data, 0)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, n_channels, latent_vec_size, feat_map_size):\n","        super(Generator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d(latent_vec_size, feat_map_size * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 8),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(feat_map_size * 8, feat_map_size * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 4),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(feat_map_size * 4, feat_map_size * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 2),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(feat_map_size * 2, feat_map_size, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(feat_map_size, n_channels, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, n_channels, feat_map_size):\n","        super(Discriminator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(n_channels, feat_map_size, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(feat_map_size, feat_map_size * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(feat_map_size * 2, feat_map_size * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(feat_map_size * 4, feat_map_size * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(feat_map_size * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","\n","def latency(model, sample):\n","\tstart = torch.cuda.Event(enable_timing=True)\n","\tend = torch.cuda.Event(enable_timing=True)\n","\tstart.record()\n","\t_ = model(sample)\n","\tend.record()\n","\ttorch.cuda.synchronize()\n","\treturn start.elapsed_time(end)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Rb9RxCDutv1r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736383579035,"user_tz":-60,"elapsed":12,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"392b925a-dd8b-488c-be0a-45fc113c4e6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["device count: 1\n","GPU Tesla T4 available with compatibility (7, 5)\n","GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\n"]}],"source":["if torch.cuda.is_available():\n","    print('device count:', torch.cuda.device_count())\n","    device = torch.device(0)\n","    device_cap = torch.cuda.get_device_capability()\n","    print(f\"GPU {torch.cuda.get_device_name(0)} available with compatibility {device_cap}\")\n","    if device_cap not in ((7, 0), (8, 0), (9, 0)):\n","        print(\"GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU unavailable\")"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"YvEVZMN7twlI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736383579035,"user_tz":-60,"elapsed":10,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"46dd9a27-bc56-47fe-a69e-2b0d4bdbb47e"},"outputs":[{"output_type":"stream","name":"stdout","text":["1736383578100084184\n"]}],"source":["nc = 3\n","nz = 100\n","ngf = 64\n","ndf = 64\n","latent_vec_size = 100\n","\n","batch_size = 96\n","lr = 1e-4\n","gen_batch_size = 1024\n","epochs = 12\n","log_interval = 200\n","timestamp = time.time_ns()\n","print(timestamp)\n","results_eager_filepath = f'./drive/MyDrive/colab/results/pytorch-dcgan-eager-{timestamp}.csv'\n","results_compile_filepath = f'./drive/MyDrive/colab/results/pytorch-dcgan-compile-{timestamp}.csv'\n","start = torch.cuda.Event(enable_timing=True)\n","end = torch.cuda.Event(enable_timing=True)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Dr6wxDPRvGZc","executionInfo":{"status":"ok","timestamp":1736383814242,"user_tz":-60,"elapsed":235214,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"outputs":[],"source":["celeba_dl = get_celeba_loader_from_memory(batch_size=batch_size, root='./drive/MyDrive/colab/datasets/celeba_tiny')\n","# takes a loooot of time thus separate code block"]},{"cell_type":"markdown","metadata":{"id":"Bw58hMDvvjAB"},"source":["## Training - eager mode"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SnSrEJtvpna","executionInfo":{"status":"ok","timestamp":1736384107778,"user_tz":-60,"elapsed":293539,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"ece99ce2-2735-44a4-d0f3-a00485a9760a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 finished with execution time of 23.925658203125s\n","Epoch 2 finished with execution time of 24.041216796875s\n","Epoch 3 finished with execution time of 24.91909765625s\n","Epoch 4 finished with execution time of 24.5904765625s\n","Epoch 5 finished with execution time of 24.383412109375s\n","Epoch 6 finished with execution time of 24.484994140625s\n","Epoch 7 finished with execution time of 24.552009765625s\n","Epoch 8 finished with execution time of 24.470908203125s\n","Epoch 9 finished with execution time of 24.415533203125s\n","Epoch 10 finished with execution time of 24.5228984375s\n","Epoch 11 finished with execution time of 24.548359375s\n","Epoch 12 finished with execution time of 24.525701171875s\n"]}],"source":["telemetry_eager = defaultdict(list)\n","\n","netG = Generator(nc, nz, ngf).to(device)\n","netD = Discriminator(nc, ndf).to(device)\n","netG.apply(dcgan_weights_init)\n","netD.apply(dcgan_weights_init)\n","netG.train()\n","netD.train()\n","\n","loss_func = nn.BCELoss()\n","optG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n","optD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n","\n","for epoch in range(1, epochs + 1):\n","  running_stats = [0 for _ in range(5)]\n","  start.record()\n","  for xb in celeba_dl:\n","    xb = xb[0].to(device)\n","    stats = fit_dcgan_step(netG, netD, device, xb, loss_func, optG, optD, latent_vec_size)\n","\n","    for i, stat in enumerate(stats):\n","      running_stats[i] += stat\n","  end.record()\n","  torch.cuda.synchronize()\n","\n","  for i, stat in enumerate(running_stats):\n","    running_stats[i] = stat / len(celeba_dl)\n","\n","  telemetry_eager['model_name'].append('DCGAN')\n","  telemetry_eager['phase'].append('training')\n","  telemetry_eager['epoch'].append(epoch)\n","  telemetry_eager['loss'].append(f'{running_stats[0]}|{running_stats[1]}')\n","  telemetry_eager['performance'].append(f'{running_stats[2]}|{running_stats[3]}|{running_stats[4]}')\n","  telemetry_eager['elapsed_time'].append(start.elapsed_time(end))\n","  print(f'Epoch {epoch} finished with execution time of {start.elapsed_time(end) / 1e3}s')\n","pd.DataFrame(telemetry_eager).to_csv(results_eager_filepath, index=False)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"msqJ7f2PBPrb","executionInfo":{"status":"ok","timestamp":1736384107779,"user_tz":-60,"elapsed":11,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"80eb411a-bd1b-4479-bc8f-0bb331302488"},"outputs":[{"output_type":"stream","name":"stdout","text":["eager: 12\n"]}],"source":["print(\"eager:\", len(telemetry_eager[\"phase\"]))\n","# 12 epochs of training"]},{"cell_type":"markdown","metadata":{"id":"ChAvRyPVmUJn"},"source":["## Latency - both modes"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"WayJkDR1VW_g","executionInfo":{"status":"ok","timestamp":1736384107779,"user_tz":-60,"elapsed":8,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"outputs":[],"source":["telemetry_compile = defaultdict(list)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ceMklhYHmV6p","executionInfo":{"status":"ok","timestamp":1736384110678,"user_tz":-60,"elapsed":2906,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"ce944b87-f360-4e01-89ab-f1f2b743344f"},"outputs":[{"output_type":"stream","name":"stdout","text":["compilation - eager mode: 1.3968960046768188\n","compilation - compile mode: 926.9678344726562\n","median exec time (e/c): 0.582431972026825 / 0.7720959782600403\n","compiled graph is on average 0.7543517754610853 times faster than eager execution\n"]}],"source":["warmup = 1000\n","netG = Generator(nc, nz, ngf).to(device)\n","netG.apply(dcgan_weights_init)\n","torch._dynamo.reset()\n","netG_comp = torch.compile(netG, mode='reduce-overhead')\n","netG.eval()\n","\n","latent_vecs = torch.randn(epochs + warmup + 1, latent_vec_size, 1, 1, device=device)\n","# latent_vecs[0].unsqueeze(0).size()\n","\n","telemetry_eager_times = []\n","telemetry_compile_times = []\n","\n","# compilation\n","with torch.no_grad():\n","  e = latency(netG, latent_vecs[-1].unsqueeze(0))\n","  print('compilation - eager mode:', e)\n","  telemetry_eager_times.append(e)\n","\n","  c = latency(netG_comp, latent_vecs[-1].unsqueeze(0))\n","  print('compilation - compile mode:', c)\n","  telemetry_compile_times.append(c)\n","\n","  for i in range(epochs + warmup):\n","    # warmup\n","    e = latency(netG, latent_vecs[1].unsqueeze(0))\n","    c = latency(netG_comp, latent_vecs[i].unsqueeze(0))\n","\n","    # latency\n","    if i >= warmup:\n","        telemetry_eager_times.append(e)\n","        telemetry_compile_times.append(c)\n","\n","em = np.median(telemetry_eager_times)\n","cm = np.median(telemetry_compile_times)\n","print(f'median exec time (e/c): {em} / {cm}')\n","print(f'compiled graph is on average {em / cm} times faster than eager execution')\n","\n","\n","# telemetry\n","for telemetry, telemetry_times in [(telemetry_eager, telemetry_eager_times),\n","                                   (telemetry_compile, telemetry_compile_times)]:\n","  telemetry['model_name'].extend([\"DCGAN\"] * (epochs + 1))\n","  telemetry['phase'].extend(['graph_compilation'] + ['latency'] * epochs)\n","  telemetry['epoch'].extend([1] + list(range(1, epochs + 1)))\n","  telemetry['loss'].extend([-1] * (epochs + 1))\n","  telemetry['performance'].extend([-1] * (epochs + 1))\n","  telemetry['elapsed_time'].extend(telemetry_times)\n","\n","pd.DataFrame(telemetry_compile).to_csv(results_compile_filepath, index=False)\n","pd.DataFrame(telemetry_eager).to_csv(results_eager_filepath, index=False)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CoW16aykB24_","executionInfo":{"status":"ok","timestamp":1736384110678,"user_tz":-60,"elapsed":8,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"ec5db811-c9db-462a-d39e-9215ae13125b"},"outputs":[{"output_type":"stream","name":"stdout","text":["eager: 25\n","compile: 13\n"]}],"source":["print(\"eager:\", len(telemetry_eager[\"phase\"]))\n","# 12 + 1 + 12 = 25\n","print(\"compile:\", len(telemetry_compile[\"phase\"]))\n","# 1 + 12 = 13"]},{"cell_type":"markdown","metadata":{"id":"VJy-ZEihX2IR"},"source":["## Latency on batch - both modes"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"pXm3GVvqSLAY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736384466456,"user_tz":-60,"elapsed":355783,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"02f01e55-a631-4f4a-c8d8-fab8b8109708"},"outputs":[{"output_type":"stream","name":"stdout","text":["compilation - eager mode: 153.63352966308594\n","compilation - compile mode: 983.257080078125\n","median exec time (e/c): 172.60707092285156 / 176.80181884765625\n","compiled graph is on average 0.9762742942796355 times faster than eager execution\n"]}],"source":["warmup = 1000\n","netG = Generator(nc, nz, ngf).to(device)\n","netG.apply(dcgan_weights_init)\n","torch._dynamo.reset()\n","netG_comp = torch.compile(netG, mode='reduce-overhead')\n","netG.eval()\n","\n","telemetry_eager_times = []\n","telemetry_compile_times = []\n","\n","# compilation\n","with torch.no_grad():\n","  latent_vec = torch.randn(1024, latent_vec_size, 1, 1, device=device)\n","  e = latency(netG, latent_vecs)\n","  print('compilation - eager mode:', e)\n","  telemetry_eager_times.append(e)\n","\n","  c = latency(netG_comp, latent_vec)\n","  print('compilation - compile mode:', c)\n","  telemetry_compile_times.append(c)\n","\n","  for i in range(epochs + warmup):\n","    latent_vec = torch.randn(1024, latent_vec_size, 1, 1, device=device)\n","    # warmup\n","    e = latency(netG, latent_vec)\n","    c = latency(netG_comp, latent_vec)\n","\n","    # latency\n","    if i >= warmup:\n","        telemetry_eager_times.append(e)\n","        telemetry_compile_times.append(c)\n","\n","em = np.median(telemetry_eager_times)\n","cm = np.median(telemetry_compile_times)\n","print(f'median exec time (e/c): {em} / {cm}')\n","print(f'compiled graph is on average {em / cm} times faster than eager execution')\n","\n","\n","# telemetry\n","for telemetry, telemetry_times in [(telemetry_eager, telemetry_eager_times),\n","                                   (telemetry_compile, telemetry_compile_times)]:\n","  telemetry['model_name'].extend([\"DCGAN\"] * (epochs + 1))\n","  telemetry['phase'].extend(['graph_compilation_batch'] + ['latency_batch'] * epochs)\n","  telemetry['epoch'].extend([1] + list(range(1, epochs + 1)))\n","  telemetry['loss'].extend([-1] * (epochs + 1))\n","  telemetry['performance'].extend([-1] * (epochs + 1))\n","  telemetry['elapsed_time'].extend(telemetry_times)\n","\n","pd.DataFrame(telemetry_compile).to_csv(results_compile_filepath, index=False)\n","pd.DataFrame(telemetry_eager).to_csv(results_eager_filepath, index=False)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"Caqa32g1CB0T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736384466457,"user_tz":-60,"elapsed":7,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"4a039fb1-2652-4771-ec9d-5f18ac1d3d46"},"outputs":[{"output_type":"stream","name":"stdout","text":["eager: 38\n","compile: 26\n"]}],"source":["print(\"eager:\", len(telemetry_eager[\"phase\"]))\n","# 25 + 1 + 12 = 38\n","print(\"compile:\", len(telemetry_compile[\"phase\"]))\n","# 13 + 1 + 12 = 26"]},{"cell_type":"markdown","metadata":{"id":"2Dx0OZtnb5-6"},"source":["## Training - compile mode"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"bu0T2rszb47L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736384838867,"user_tz":-60,"elapsed":372415,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"86f0a08f-e8bc-43d4-b1a6-a2e6ab49f849"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train loop (re)started\n","Train loop (re)started\n","Epoch 1 finished with execution time of 33.33743359375s\n","Train loop (re)started\n","Epoch 1 finished with execution time of 33.1978125s\n","Epoch 2 finished with execution time of 31.108763671875s\n","Epoch 3 finished with execution time of 24.48380078125s\n","Epoch 4 finished with execution time of 24.344572265625s\n","Epoch 5 finished with execution time of 24.29173046875s\n","Epoch 6 finished with execution time of 24.301615234375s\n","Epoch 7 finished with execution time of 24.331296875s\n","Epoch 8 finished with execution time of 24.37728515625s\n","Epoch 9 finished with execution time of 24.3610390625s\n","Epoch 10 finished with execution time of 24.3971015625s\n","Epoch 11 finished with execution time of 24.369240234375s\n","Epoch 12 finished with execution time of 24.40378125s\n"]}],"source":["def train_compiled_dcgan():\n","  telemetry_compile_train = defaultdict(list)\n","  netG = Generator(nc, nz, ngf).to(device)\n","  netD = Discriminator(nc, ndf).to(device)\n","  netG.apply(dcgan_weights_init)\n","  netD.apply(dcgan_weights_init)\n","  torch._dynamo.reset()\n","  netG = torch.compile(netG, mode='reduce-overhead')\n","  netD = torch.compile(netD, mode='reduce-overhead')\n","  netG.train()\n","  netD.train()\n","\n","  loss_func = nn.BCELoss()\n","  optG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n","  optD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n","\n","  fit_dcgan_step_compiled = torch.compile(fit_dcgan_step, mode=\"reduce-overhead\")\n","\n","  for epoch in range(1, epochs + 1):\n","    running_stats = [0 for _ in range(5)]\n","    start.record()\n","    for xb in celeba_dl:\n","      xb = xb[0].to(device)\n","      torch.compiler.cudagraph_mark_step_begin()\n","      stats = fit_dcgan_step(netG, netD, device, xb, loss_func, optG, optD, latent_vec_size)\n","\n","      for i, stat in enumerate(stats):\n","        running_stats[i] += stat\n","    end.record()\n","    torch.cuda.synchronize()\n","\n","    for i, stat in enumerate(running_stats):\n","      running_stats[i] = stat / len(celeba_dl)\n","\n","    telemetry_compile_train['model_name'].append('DCGAN')\n","    telemetry_compile_train['phase'].append('training')\n","    telemetry_compile_train['epoch'].append(epoch)\n","    telemetry_compile_train['loss'].append(f'{running_stats[0]}|{running_stats[1]}')\n","    telemetry_compile_train['performance'].append(f'{running_stats[2]}|{running_stats[3]}|{running_stats[4]}')\n","    telemetry_compile_train['elapsed_time'].append(start.elapsed_time(end))\n","    print(f'Epoch {epoch} finished with execution time of {start.elapsed_time(end) / 1e3}s')\n","\n","  return telemetry_compile_train\n","\n","def train_try_loop() -> None:\n","  print(\"Train loop (re)started\")\n","  try:\n","    telemetry_compile_train = train_compiled_dcgan()\n","  except RuntimeError:\n","    train_try_loop()\n","  else:\n","    for key, arr in telemetry_compile_train.items():\n","      telemetry_compile[key].extend(arr)\n","\n","train_try_loop()"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"vb9owRurXFwC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736384838867,"user_tz":-60,"elapsed":7,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"469695ca-80f4-4108-d851-e098759b6836"},"outputs":[{"output_type":"stream","name":"stdout","text":["compile: 38\n"]}],"source":["print(\"compile:\", len(telemetry_compile[\"phase\"]))\n","# 26 + 12 = 38\n","\n","pd.DataFrame(telemetry_compile).to_csv(results_compile_filepath, index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}