{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%pip uninstall torch -y -q\n","%pip install triton==3.1.0 -q\n","%pip install torch==2.5.1 -q\n","\n","%pip install torchinfo --quiet\n","%pip install ultralytics --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xc5PeQBuKwL7","executionInfo":{"status":"ok","timestamp":1725224342602,"user_tz":-120,"elapsed":211095,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"c0dd9664-07e4-41e8-a874-5cb911343639"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.0/872.0 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10478,"status":"ok","timestamp":1725224363667,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"},"user_tz":-120},"id":"zSqyxjsM6mUo","outputId":"a14b3e13-3838-442e-ed98-88101f8e32f5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x7a0095a07100>"]},"metadata":{},"execution_count":4}],"source":["import torch\n","from torchinfo import summary\n","from ultralytics import YOLO\n","from torchvision.io import read_image\n","from torchvision.transforms import Resize, Compose\n","from torch.utils.data import Dataset\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","from collections import defaultdict\n","import pandas as pd\n","import time\n","from tqdm import tqdm, trange\n","\n","torch.set_grad_enabled(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1725224363668,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"},"user_tz":-120},"id":"EvL5YKh-WvVJ","outputId":"fad494e1-7d86-4bd7-d58d-a223a8f19089"},"outputs":[{"output_type":"stream","name":"stdout","text":["device count: 1\n","GPU Tesla T4 available with compatibility (7, 5)\n","GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\n"]}],"source":["if torch.cuda.is_available():\n","    print('device count:', torch.cuda.device_count())\n","    device = torch.device(0)\n","    device_cap = torch.cuda.get_device_capability()\n","    print(f\"GPU {torch.cuda.get_device_name(0)} available with compatibility {device_cap}\")\n","    if device_cap not in ((7, 0), (8, 0), (9, 0)):\n","        print(\"GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU unavailable\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nTKhsppXqZ1L"},"outputs":[],"source":["class Coco2017Dataset(Dataset):\n","  def __init__(self, img_dir: str, transform=None) -> None:\n","    assert (p := Path(img_dir)).exists() and p.is_dir(), f\"Image directory {img_dir} does not exist\"\n","    self.img_paths = [str(p) for p in Path(img_dir).glob(\"*.jpg\")]\n","    self.transform = transform\n","\n","  def __len__(self) -> int:\n","    return len(self.img_paths)\n","\n","  def __getitem__(self, idx: int) -> torch.Tensor:\n","    img_path = self.img_paths[idx]\n","    img = read_image(img_path)\n","    if self.transform:\n","        img = self.transform(img / 255).to(torch.float32)\n","    return img\n","\n","\n","class Expand(object):\n","  def __call__(self, sample: torch.Tensor) -> torch.Tensor:\n","    if sample.size()[0] != 3:\n","      deep_copy = sample.detach().clone()\n","      return deep_copy.expand(3, -1, -1)\n","    else:\n","      return sample\n","\n","\n","def latency(model, sample):\n","  start = torch.cuda.Event(enable_timing=True)\n","  end = torch.cuda.Event(enable_timing=True)\n","\n","  start.record()\n","  res = model.predict(sample, verbose=False)\n","  end.record()\n","  torch.cuda.synchronize()\n","  full_elapsed_time = start.elapsed_time(end)\n","\n","  infer_elapsed_time = res[0].speed[\"inference\"]\n","  return full_elapsed_time, infer_elapsed_time"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":708,"status":"ok","timestamp":1725224603356,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"},"user_tz":-120},"id":"glNoRLTorsUj","outputId":"974bf31d-029d-4ccf-c305-5d4aa3253bee"},"outputs":[{"output_type":"stream","name":"stdout","text":["1725224601861425976\n"]}],"source":["coco_ds = Coco2017Dataset(\n","  img_dir=\"/content/drive/MyDrive/colab/datasets/coco2017_val\",\n","  transform=Compose([\n","      Resize(size=(640, 640), antialias=True),\n","      Expand()\n","  ])\n",")\n","# plt.imshow(coco_ds[0].permute(1, 2, 0))\n","\n","start = torch.cuda.Event(enable_timing=True)\n","end = torch.cuda.Event(enable_timing=True)\n","\n","timestamp = time.time_ns()\n","print(timestamp)\n","results_filepath = f'/content/drive/MyDrive/colab/results/pytorch-yolo-{timestamp}.csv'\n","telemetry = defaultdict(list)"]},{"cell_type":"markdown","metadata":{"id":"ImMF_S8HfYQ2"},"source":["## YOLOv8 latency in PyTorch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1717444,"status":"ok","timestamp":1725223226805,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"},"user_tz":-120},"id":"5NQtYShGfLhV","outputId":"4a0c3724-3cda-404c-a2c6-1f099f2ee2b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 49.7M/49.7M [00:00<00:00, 124MB/s]\n","Benchmark: 100%|██████████| 5000/5000 [28:35<00:00,  2.91it/s]\n"]}],"source":["model = YOLO(\"yolov8m.pt\", verbose=False).to(device)\n","assert model.device.type == \"cuda\"\n","\n","# 5k warmup\n","# for img in tqdm(coco_ds, desc=\"Warmup\"):\n","#   img = img.unsqueeze(dim=0).to(device)\n","#   _ = model.predict(img, device=device)\n","# with 5k images warmup not necessary on second thought\n","\n","# latency benchmark\n","for i, img in enumerate(tqdm(coco_ds, desc=\"Benchmark\"), start=1):\n","  img = img.unsqueeze(dim=0).to(device)\n","\n","  start.record()\n","  res = model.predict(img, device=device, verbose=False)\n","  end.record()\n","  torch.cuda.synchronize()\n","\n","  telemetry[\"framework\"].append(\"PyTorch\")\n","  telemetry[\"model_name\"].append(\"YOLOv8m\")\n","  telemetry[\"phase\"].append(\"latency\")\n","  telemetry[\"epoch\"].append(i)\n","  telemetry[\"loss\"].append(-1)\n","  telemetry[\"performance\"].append(start.elapsed_time(end))  # idk who cares how much those times differ but i wanna see\n","  telemetry[\"elapsed_time\"].append(res[0].speed[\"inference\"])"]},{"cell_type":"markdown","metadata":{"id":"0GEcgAXefjdK"},"source":["## YOLOv8 latency in PyTorch with `torch.compile`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":182894,"status":"ok","timestamp":1725223409695,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"},"user_tz":-120},"id":"DODGJT0Kb0u-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d18d3bd5-567d-4a84-8dd6-78dd9ab2f1f5"},"outputs":[{"output_type":"stream","name":"stderr","text":["Compiled benchmark: 100%|██████████| 5000/5000 [03:00<00:00, 27.77it/s]"]},{"output_type":"stream","name":"stdout","text":["Runtime error count: 0 (100.0%)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["model = YOLO(\"yolov8m.pt\", verbose=False).to(device)\n","torch._dynamo.reset()\n","model.model = torch.compile(model.model, mode=\"reduce-overhead\")\n","assert model.device.type == \"cuda\"\n","\n","# 5k warmup\n","# for img in tqdm(coco_ds, desc=\"Warmup\"):\n","#   img = img.unsqueeze(dim=0).to(device)\n","#   stuck = True\n","#   while stuck:\n","#       try:\n","#         start.record()\n","#         res = model.predict(img, device=device)\n","#         end.record()\n","#         torch.cuda.synchronize()\n","#       except: pass\n","#       else: stuck = False\n","# with 5k images warmup not necessary on second thought\n","\n","# latency benchmark\n","runtime_errors = 0\n","for i, img in enumerate(tqdm(coco_ds, desc=\"Compiled benchmark\"), start=1):\n","  img = img.unsqueeze(dim=0).to(device)\n","\n","  stuck = True\n","  while stuck:\n","      try:\n","        start.record()\n","        res = model.predict(img, device=device, verbose=False)\n","        end.record()\n","        torch.cuda.synchronize()\n","      except:\n","        runtime_errors += 1\n","      else: stuck = False\n","\n","  telemetry[\"framework\"].append(\"PyTorch_compile\")\n","  telemetry[\"model_name\"].append(\"YOLOv8m\")\n","  telemetry[\"phase\"].append(\"latency\")\n","  telemetry[\"epoch\"].append(i)\n","  telemetry[\"loss\"].append(-1)\n","  telemetry[\"performance\"].append(start.elapsed_time(end))  # idk who cares how much those times differ but i wanna see\n","  telemetry[\"elapsed_time\"].append(res[0].speed[\"inference\"])\n","\n","print(f\"Runtime error count: {runtime_errors} ({(runtime_errors + len(coco_ds)) / len(coco_ds) * 100}%)\")"]},{"cell_type":"markdown","metadata":{"id":"5MyLHiO7qges"},"source":["## Graph compilation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14549,"status":"ok","timestamp":1725224798006,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"},"user_tz":-120},"id":"e-iD6j_hd4K8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9d3a138e-eb1c-4deb-ce3c-bd6a49442af4"},"outputs":[{"output_type":"stream","name":"stderr","text":["Graph compilaton: 100%|██████████| 12/12 [00:14<00:00,  1.19s/it]\n"]}],"source":["for i in tqdm(range(12), desc=\"Graph compilaton\"):\n","  sample = coco_ds[i]\n","  sample = sample.unsqueeze(dim=0).to(device)\n","\n","  model = YOLO(\"yolov8m.pt\", verbose=False).to(device)\n","  model_comp = YOLO(\"yolov8m.pt\", verbose=False).to(device)\n","  torch._dynamo.reset()\n","  model_comp.model = torch.compile(model_comp.model, mode=\"reduce-overhead\")\n","\n","  e_full, e_infer = latency(model, sample)\n","  c_full, c_infer = latency(model_comp, sample)\n","\n","  telemetry[\"framework\"].extend([\"PyTorch\", \"PyTorch_compile\"])\n","  telemetry[\"model_name\"].extend([\"YOLOv8m\", \"YOLOv8m\"])\n","  telemetry[\"phase\"].extend([\"graph_compilation\", \"graph_compilation\"])\n","  telemetry[\"epoch\"].extend([i, i])\n","  telemetry[\"loss\"].extend([-1, -1])\n","  telemetry[\"performance\"].extend([e_full, c_full])\n","  telemetry[\"elapsed_time\"].extend([e_infer, c_infer])\n","\n","pd.DataFrame(telemetry).to_csv(results_filepath, index=False)"]},{"cell_type":"markdown","source":["## Warm up\n"],"metadata":{"id":"_N6C2aSrwezh"}},{"cell_type":"code","source":["for _ in trange(12):\n","  model = YOLO(\"yolov8m.pt\", verbose=False).to(device)\n","  model_comp = YOLO(\"yolov8m.pt\", verbose=False).to(device)\n","  torch._dynamo.reset()\n","  model_comp.model = torch.compile(model_comp.model, mode=\"reduce-overhead\")\n","\n","  for i in range(1, 21):\n","    sample = coco_ds[i].unsqueeze(dim=0).to(device)\n","\n","    e_full, e_infer = latency(model, sample)\n","    c_full, c_infer = latency(model_comp, sample)\n","\n","    telemetry[\"framework\"].extend([\"PyTorch\", \"PyTorch_compile\"])\n","    telemetry[\"model_name\"].extend([\"YOLOv8m\", \"YOLOv8m\"])\n","    telemetry[\"phase\"].extend([\"warmup\", \"warmup\"])\n","    telemetry[\"epoch\"].extend([i, i])\n","    telemetry[\"loss\"].extend([-1, -1])\n","    telemetry[\"performance\"].extend([e_full, c_full])\n","    telemetry[\"elapsed_time\"].extend([e_infer, c_infer])\n","\n","pd.DataFrame(telemetry).to_csv(results_filepath, index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWE0q9xqwec4","executionInfo":{"status":"ok","timestamp":1725223436827,"user_tz":-120,"elapsed":20812,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"0fd009ff-3008-4abf-c3da-31fb1595e2b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 12/12 [00:20<00:00,  1.72s/it]\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}