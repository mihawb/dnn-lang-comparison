{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, densenet121, mobilenet_v2, convnext_small\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch_funcs import fit, test, get_cifar10_loaders, get_mnist_loaders, FullyConnectedNet, SimpleConvNet\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA enabled: True\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "test_batch_size = 64\n",
    "epochs = 2\n",
    "lr = 1e-2\n",
    "momentum = 0.9\n",
    "num_classes = 10\n",
    "log_interval = 300\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f'CUDA enabled: {use_cuda}')\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch: 1 -> batch: 299 [9568/50000 (19%)]\tLoss: 2.615775\n",
      "Train Epoch: 1 -> batch: 599 [19168/50000 (38%)]\tLoss: 2.239391\n",
      "Train Epoch: 1 -> batch: 899 [28768/50000 (58%)]\tLoss: 2.051182\n",
      "Train Epoch: 1 -> batch: 1199 [38368/50000 (77%)]\tLoss: 1.929848\n",
      "Train Epoch: 1 -> batch: 1499 [47968/50000 (96%)]\tLoss: 1.779341\n",
      "\n",
      "Test set: Average loss: 1.6362, Accuracy: 4110/10000 (41%)\n",
      "\n",
      "Train Epoch: 2 -> batch: 299 [9568/50000 (19%)]\tLoss: 1.658011\n",
      "Train Epoch: 2 -> batch: 599 [19168/50000 (38%)]\tLoss: 1.626790\n",
      "Train Epoch: 2 -> batch: 899 [28768/50000 (58%)]\tLoss: 1.592216\n",
      "Train Epoch: 2 -> batch: 1199 [38368/50000 (77%)]\tLoss: 1.538345\n",
      "Train Epoch: 2 -> batch: 1499 [47968/50000 (96%)]\tLoss: 1.546808\n",
      "\n",
      "Test set: Average loss: 1.4908, Accuracy: 4602/10000 (46%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = mobilenet_v2()\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n",
    "train_dl, test_dl = get_cifar10_loaders(batch_size, test_batch_size)\n",
    "loss_func = F.cross_entropy\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "\ttrain_history = fit(model, device, train_dl, loss_func, epoch, optimizer=opt, log_interval=log_interval, silent=False)\n",
    "\t_, accuracy = test(model, device, test_dl, loss_func, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_celeba_loader(batch_size, image_size=64):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(image_size),\n",
    "        torchvision.transforms.CenterCrop(image_size),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.stransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    ds = torchvision.datasets.ImageFolder(root='../datasets/celeba', transform=transform)\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    return dl\n",
    "\n",
    "\n",
    "def dcgan_weights_init(model):\n",
    "    '''\n",
    "    From the DCGAN paper, the authors specify that all model weights shall be\n",
    "    randomly initializedfrom a Normal distribution with `mean=0`, `stdev=0.02`\n",
    "    '''\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nc, nz, ngf):\n",
    "        '''\n",
    "        nz - latent vector size\n",
    "        nc - number of channels\n",
    "        ngf - size of feature maps in generator\n",
    "        '''\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nz, nc, ndf):\n",
    "        '''\n",
    "        nz - latent vector size\n",
    "        nc - number of channels\n",
    "        ndf - size of feature maps in discriminator\n",
    "        '''\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is ``(nc) x 64 x 64``\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf) x 32 x 32``\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*2) x 16 x 16``\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*4) x 8 x 8``\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*8) x 4 x 4``\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 3\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(nc, nz, ngf).to(device)\n",
    "netD = Discriminator(nc, nz, ngf).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
