{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.models import mobilenet_v2, resnet50\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch_funcs import fit, fit_dcgan, test, get_cifar10_loaders, get_mnist_loaders, get_celeba_loader, Discriminator, Generator, dcgan_weights_init, FullyConnectedNet, SimpleConvNet\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA enabled: True\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "test_batch_size = 128\n",
    "epochs = 2\n",
    "lr = 1e-2\n",
    "momentum = 0.9\n",
    "num_classes = 10\n",
    "log_interval = 300\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f'CUDA enabled: {use_cuda}')\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=10, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mobilenet_v2()\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n",
    "model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1]\t[299/391 (76%)]\tLoss 1.9573\n",
      "\n",
      "Test set: Average loss: 1.7064, Accuracy: 3994/10000 (40%)\n",
      "\n",
      "[2]\t[299/391 (76%)]\tLoss 1.5885\n",
      "\n",
      "Test set: Average loss: 1.4675, Accuracy: 4637/10000 (46%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = mobilenet_v2()\n",
    "# model.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n",
    "train_dl, test_dl = get_cifar10_loaders(batch_size, test_batch_size)\n",
    "loss_func = F.cross_entropy\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "\ttrain_history = fit(model, device, train_dl, loss_func, epoch, optimizer=opt, log_interval=log_interval, silent=False)\n",
    "\t_, accuracy = test(model, device, test_dl, loss_func, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 3\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "lr = 1e-2\n",
    "log_interval = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(nc, nz, ngf).to(device)\n",
    "netD = Discriminator(nc, ndf).to(device)\n",
    "netG.apply(dcgan_weights_init)\n",
    "netD.apply(dcgan_weights_init)\n",
    "\n",
    "celeba_dl = get_celeba_loader(batch_size=batch_size)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "fixed_noise = torch.randn(32, nz, 1, 1, device=device)\n",
    "real_label = 1.\n",
    "fake_label = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1][99/1583]\tLoss_G: 20.9807\tLoss_D: 17.4933\tD(x): 0.9396\tD(G(z)): 0.9901 / 0.0000\n",
      "[1][199/1583]\tLoss_G: 1.6358\tLoss_D: 1.5231\tD(x): 0.6286\tD(G(z)): 0.5497 / 0.2520\n",
      "[1][299/1583]\tLoss_G: 2.6232\tLoss_D: 1.4367\tD(x): 0.7221\tD(G(z)): 0.6102 / 0.0965\n",
      "[1][399/1583]\tLoss_G: 1.9194\tLoss_D: 1.0152\tD(x): 0.6282\tD(G(z)): 0.3770 / 0.1866\n",
      "[1][499/1583]\tLoss_G: 1.3397\tLoss_D: 1.2172\tD(x): 0.5535\tD(G(z)): 0.4198 / 0.2965\n",
      "[1][599/1583]\tLoss_G: 1.7822\tLoss_D: 1.2879\tD(x): 0.5427\tD(G(z)): 0.4340 / 0.1995\n",
      "[1][699/1583]\tLoss_G: 1.8630\tLoss_D: 1.1133\tD(x): 0.6079\tD(G(z)): 0.3988 / 0.1806\n",
      "[1][799/1583]\tLoss_G: 1.5708\tLoss_D: 1.0646\tD(x): 0.5325\tD(G(z)): 0.2591 / 0.2383\n",
      "[1][899/1583]\tLoss_G: 1.3710\tLoss_D: 1.0870\tD(x): 0.6051\tD(G(z)): 0.3872 / 0.2870\n",
      "[1][999/1583]\tLoss_G: 2.1518\tLoss_D: 1.4688\tD(x): 0.8437\tD(G(z)): 0.6660 / 0.1411\n",
      "[1][1099/1583]\tLoss_G: 2.9441\tLoss_D: 0.6247\tD(x): 0.8011\tD(G(z)): 0.2805 / 0.0697\n",
      "[1][1199/1583]\tLoss_G: 1.5885\tLoss_D: 1.1115\tD(x): 0.6447\tD(G(z)): 0.4343 / 0.2401\n",
      "[1][1299/1583]\tLoss_G: 3.3159\tLoss_D: 0.8271\tD(x): 0.8099\tD(G(z)): 0.4118 / 0.0509\n",
      "[1][1399/1583]\tLoss_G: 2.4273\tLoss_D: 0.6954\tD(x): 0.7376\tD(G(z)): 0.2737 / 0.1030\n",
      "[1][1499/1583]\tLoss_G: 2.6166\tLoss_D: 1.3415\tD(x): 0.7564\tD(G(z)): 0.5878 / 0.0917\n"
     ]
    }
   ],
   "source": [
    "train_history = fit_dcgan(netG, netD, device, celeba_dl, criterion, 1, optimizerG, optimizerD, nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_hist = train_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stat in gan_hist:\n",
    "\tgan_hist[stat] = np.sum(gan_hist[stat]) / len(gan_hist[stat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_G': 2.7734051945706213,\n",
       " 'loss_D': 1.810619429906209,\n",
       " 'D_x': 0.615383079831799,\n",
       " 'D_G_z1': 0.39280968859269344,\n",
       " 'D_G_z2': 0.1983502202280846}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate(generator, device, epoch, test_batch_size=64, latent_vec_size=100, latent_vecs_batch=None, save=False):\n",
    "\t# batch size not smaller than 64\n",
    "\tif latent_vecs_batch is None:\n",
    "\t\tlatent_vecs_batch = torch.randn(test_batch_size, latent_vec_size, 1, 1, device=device)\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tres_imgs = generator(latent_vecs_batch).detach().cpu()\n",
    "\n",
    "\tif save:\n",
    "\t\tplt.imsave(\n",
    "\t\t\tf'dcgan_results_{epoch}.png',\n",
    "\t\t\tnp.transpose(torchvision.utils.make_grid(res_imgs[:64], padding=5, normalize=True).cpu().numpy(),(1,2,0))\n",
    "\t\t)\n",
    "\n",
    "\treturn res_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.2118e-02,  8.6004e-03,  3.7412e-02,  ..., -5.4062e-02,\n",
       "           -4.6361e-02, -2.8272e-02],\n",
       "          [-1.3394e-01, -3.0376e-03, -1.1378e-02,  ..., -8.2522e-02,\n",
       "           -1.5888e-01, -3.2754e-02],\n",
       "          [-1.2866e-01,  6.6994e-02, -1.2644e-02,  ...,  1.5813e-01,\n",
       "           -7.9679e-02,  5.2888e-02],\n",
       "          ...,\n",
       "          [-1.5073e-01,  1.3896e-02, -1.2250e-01,  ...,  9.9944e-02,\n",
       "           -1.4910e-01, -2.5331e-02],\n",
       "          [-2.2356e-02,  2.9874e-02,  2.7379e-02,  ...,  6.1006e-02,\n",
       "           -6.3017e-02,  9.0628e-02],\n",
       "          [-4.3097e-02, -5.9198e-02, -7.1866e-02,  ..., -7.1192e-02,\n",
       "           -2.7492e-02,  2.0440e-03]],\n",
       "\n",
       "         [[ 1.8903e-02, -4.3201e-02,  3.6508e-02,  ..., -6.6337e-03,\n",
       "            9.5754e-02, -4.0153e-02],\n",
       "          [-9.1757e-02,  1.5427e-02, -8.6518e-02,  ..., -7.1426e-02,\n",
       "           -1.2825e-01,  2.7103e-03],\n",
       "          [ 6.0902e-02, -6.4151e-03, -2.4467e-02,  ..., -7.1040e-02,\n",
       "            7.3550e-03, -2.6617e-02],\n",
       "          ...,\n",
       "          [-4.7979e-02,  5.3309e-02, -2.3499e-02,  ...,  1.4630e-01,\n",
       "           -1.3636e-01, -1.1981e-02],\n",
       "          [ 4.6433e-02, -4.0704e-02,  8.9354e-02,  ..., -5.0476e-02,\n",
       "            3.8898e-02, -1.1265e-01],\n",
       "          [-3.5853e-02,  1.2342e-01, -3.7372e-02,  ...,  8.7660e-02,\n",
       "           -1.2428e-01,  6.7205e-02]],\n",
       "\n",
       "         [[-5.1057e-02, -3.5038e-02, -1.1546e-01,  ...,  5.9807e-03,\n",
       "           -1.3159e-01,  1.1797e-02],\n",
       "          [-8.5548e-02,  1.0652e-02, -2.2360e-01,  ..., -3.1811e-02,\n",
       "            2.0682e-02, -9.3845e-02],\n",
       "          [-2.3275e-02, -1.0512e-01,  5.2077e-02,  ..., -4.2307e-02,\n",
       "           -1.2158e-02, -1.4038e-01],\n",
       "          ...,\n",
       "          [-6.9071e-02,  6.0106e-02, -9.9840e-02,  ...,  2.1674e-02,\n",
       "           -1.0206e-02, -4.6683e-03],\n",
       "          [-2.4441e-03, -1.1407e-01,  6.8941e-02,  ..., -8.0244e-02,\n",
       "           -2.9356e-02, -4.2838e-02],\n",
       "          [-1.2687e-02, -3.0498e-02, -3.2749e-02,  ..., -6.8369e-02,\n",
       "           -8.3066e-04, -4.4275e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.7095e-03,  1.2610e-02,  2.1710e-02,  ..., -4.0138e-02,\n",
       "           -2.5367e-02, -3.6441e-02],\n",
       "          [-9.7438e-02, -5.9966e-02, -1.9509e-02,  ...,  1.5817e-03,\n",
       "           -1.3723e-01, -2.2429e-02],\n",
       "          [-8.8522e-02,  1.0910e-01, -6.7243e-02,  ...,  1.0033e-01,\n",
       "           -9.6814e-02,  3.4762e-02],\n",
       "          ...,\n",
       "          [-1.3339e-01,  1.8143e-02,  2.1356e-02,  ..., -7.4015e-02,\n",
       "           -1.6565e-01, -7.8755e-02],\n",
       "          [-3.3620e-02, -1.3503e-03,  1.9606e-02,  ...,  1.0751e-01,\n",
       "           -1.0373e-01,  1.4563e-01],\n",
       "          [-4.2753e-02, -5.6273e-02, -7.6047e-02,  ..., -5.0126e-02,\n",
       "           -3.2633e-02,  9.2772e-04]],\n",
       "\n",
       "         [[ 4.0381e-02, -1.2397e-02,  7.0591e-02,  ..., -1.8962e-02,\n",
       "            8.6334e-02, -3.3548e-02],\n",
       "          [ 1.7736e-03,  7.4110e-02, -1.2144e-01,  ...,  8.1290e-02,\n",
       "           -1.1552e-01, -7.0107e-02],\n",
       "          [ 6.9304e-02,  4.3046e-02, -7.6508e-02,  ..., -1.6988e-02,\n",
       "            3.2637e-02, -7.0184e-02],\n",
       "          ...,\n",
       "          [-5.4500e-02,  8.0133e-02,  1.5449e-03,  ...,  1.7437e-01,\n",
       "           -1.0721e-01,  3.0257e-02],\n",
       "          [ 4.1280e-02, -4.2221e-02,  4.6460e-02,  ...,  1.7015e-03,\n",
       "           -1.2578e-01, -4.3136e-02],\n",
       "          [-1.1624e-02,  5.8769e-02, -4.3636e-03,  ...,  4.5231e-02,\n",
       "           -4.0342e-02,  5.2928e-02]],\n",
       "\n",
       "         [[-4.5418e-02, -3.5494e-03, -3.3498e-02,  ...,  5.6055e-02,\n",
       "           -8.9923e-02,  1.0387e-02],\n",
       "          [-1.1718e-01,  1.2446e-01, -1.5270e-01,  ...,  1.1083e-01,\n",
       "            8.2975e-03, -7.7231e-02],\n",
       "          [-1.4399e-02, -5.1196e-02,  9.0634e-02,  ..., -3.5567e-02,\n",
       "            3.9227e-02, -1.2277e-01],\n",
       "          ...,\n",
       "          [-6.1180e-02,  1.3670e-01, -1.8833e-01,  ...,  2.6148e-02,\n",
       "           -6.3483e-02, -2.0974e-02],\n",
       "          [-5.1052e-02, -8.8857e-02,  3.4071e-02,  ..., -3.9165e-02,\n",
       "            1.3940e-01, -1.0438e-01],\n",
       "          [-1.8322e-02, -2.6443e-02, -2.9443e-02,  ..., -2.8997e-02,\n",
       "            2.8569e-02, -3.1219e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3253e-03,  2.1811e-02,  8.4484e-02,  ..., -6.0256e-02,\n",
       "           -3.2137e-02, -2.1746e-02],\n",
       "          [-1.1637e-01, -7.8747e-02, -5.3022e-02,  ...,  3.8638e-03,\n",
       "           -9.4147e-02, -4.5190e-02],\n",
       "          [-1.3413e-01,  3.4346e-02, -1.2528e-01,  ...,  9.3861e-03,\n",
       "           -7.8152e-02,  6.2707e-02],\n",
       "          ...,\n",
       "          [-1.7443e-01,  8.2548e-02, -2.5831e-02,  ..., -5.5745e-03,\n",
       "           -6.5699e-02, -4.8212e-02],\n",
       "          [ 2.2234e-02, -5.4364e-02,  2.8677e-02,  ..., -8.2689e-03,\n",
       "           -1.9164e-02,  5.0957e-02],\n",
       "          [-2.7155e-02, -8.5723e-02, -6.7080e-02,  ..., -4.5138e-02,\n",
       "            1.2592e-02, -5.6491e-03]],\n",
       "\n",
       "         [[ 9.0276e-03, -2.4206e-02, -2.3573e-02,  ..., -2.2452e-02,\n",
       "            7.6827e-02, -3.9987e-02],\n",
       "          [-6.7185e-02,  1.3139e-01, -2.6517e-01,  ...,  3.8530e-02,\n",
       "           -1.0628e-01,  2.2937e-02],\n",
       "          [ 6.8039e-02,  1.2127e-02, -1.7383e-02,  ...,  3.9840e-03,\n",
       "            2.9956e-03, -6.7175e-02],\n",
       "          ...,\n",
       "          [-8.4859e-02, -2.8566e-02,  4.1405e-02,  ...,  1.7707e-01,\n",
       "           -5.1093e-02,  4.6824e-02],\n",
       "          [ 5.2670e-02,  6.1903e-03,  8.1675e-02,  ..., -3.5546e-03,\n",
       "            2.1460e-02, -4.8257e-02],\n",
       "          [-4.1034e-02,  1.2389e-01,  6.5006e-03,  ...,  9.1071e-02,\n",
       "           -9.4007e-02,  5.1689e-02]],\n",
       "\n",
       "         [[-5.8418e-02, -1.8447e-02, -1.0614e-01,  ...,  3.5113e-02,\n",
       "           -7.6366e-02, -3.8322e-03],\n",
       "          [-1.0573e-01,  4.0968e-02, -2.2908e-01,  ...,  6.5826e-02,\n",
       "           -5.2020e-02, -6.7822e-02],\n",
       "          [-1.6765e-03, -1.5948e-01, -3.1620e-03,  ..., -6.3323e-02,\n",
       "            1.1800e-02, -1.0284e-01],\n",
       "          ...,\n",
       "          [-6.5965e-02,  1.1748e-01, -1.1543e-01,  ...,  1.1756e-01,\n",
       "            2.7242e-02,  3.9022e-03],\n",
       "          [ 5.5598e-02, -1.0866e-01,  3.7767e-02,  ..., -8.2178e-03,\n",
       "            2.3974e-03, -7.5818e-02],\n",
       "          [-9.2067e-03, -1.6375e-02,  3.5603e-02,  ..., -5.4351e-02,\n",
       "            9.1134e-03, -4.1834e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 2.3144e-02, -4.2306e-02,  4.7847e-03,  ..., -9.7284e-02,\n",
       "           -1.0057e-02, -2.0496e-02],\n",
       "          [-1.3016e-01, -5.1257e-02, -2.6357e-02,  ..., -9.7388e-02,\n",
       "           -9.3336e-02, -1.1895e-02],\n",
       "          [-6.0486e-02,  2.7659e-02, -9.9454e-02,  ...,  1.6797e-01,\n",
       "           -1.3899e-01,  4.2908e-02],\n",
       "          ...,\n",
       "          [-1.1948e-01, -1.1889e-01,  7.2519e-02,  ..., -5.8520e-02,\n",
       "           -1.3927e-01, -5.9338e-02],\n",
       "          [-2.0703e-02, -7.4313e-02,  3.3621e-02,  ...,  1.8122e-02,\n",
       "           -1.2009e-01,  6.8082e-03],\n",
       "          [-4.5335e-02, -8.4701e-03, -8.2244e-02,  ..., -8.9375e-02,\n",
       "           -1.1551e-02, -7.6914e-03]],\n",
       "\n",
       "         [[ 1.4956e-02, -4.6721e-02,  4.9249e-02,  ..., -2.3424e-02,\n",
       "            8.8958e-02, -3.3281e-02],\n",
       "          [-1.2027e-02,  1.2092e-02, -1.8223e-01,  ...,  3.4703e-03,\n",
       "           -1.6269e-01,  2.9377e-02],\n",
       "          [ 2.2873e-02,  1.0592e-02,  8.5945e-03,  ...,  6.1276e-02,\n",
       "           -4.5214e-02, -6.2713e-02],\n",
       "          ...,\n",
       "          [-1.6538e-02,  9.2929e-02,  5.3215e-02,  ...,  2.3097e-01,\n",
       "           -7.3339e-02, -4.0923e-03],\n",
       "          [ 2.3257e-02,  1.7876e-02,  6.7618e-02,  ..., -5.8984e-02,\n",
       "            1.3951e-02, -9.2143e-02],\n",
       "          [-4.9506e-02,  9.0450e-02, -8.4081e-02,  ...,  3.9463e-02,\n",
       "           -7.9303e-02,  5.0060e-02]],\n",
       "\n",
       "         [[-5.9001e-02, -3.4027e-02, -7.3690e-02,  ...,  2.9545e-02,\n",
       "           -4.2516e-02, -9.3801e-03],\n",
       "          [-9.1127e-02,  1.6306e-01, -1.3941e-01,  ...,  4.1522e-02,\n",
       "            9.3104e-02, -5.4041e-02],\n",
       "          [-3.2112e-05, -1.7247e-02,  1.4569e-01,  ..., -3.8196e-02,\n",
       "            4.2972e-02, -1.1409e-01],\n",
       "          ...,\n",
       "          [-6.6081e-02,  1.0415e-01, -1.5166e-01,  ...,  8.2400e-02,\n",
       "           -8.4070e-02, -4.8081e-03],\n",
       "          [-1.4180e-02, -6.7939e-02, -3.3099e-03,  ..., -5.7464e-02,\n",
       "            5.0398e-02, -1.8081e-02],\n",
       "          [-2.8821e-02, -5.2645e-02, -3.5463e-02,  ..., -5.0561e-02,\n",
       "            1.4305e-02, -2.6289e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2023e-02, -1.1007e-03, -5.9975e-03,  ..., -2.5015e-02,\n",
       "           -7.5733e-02, -1.3473e-02],\n",
       "          [-1.2994e-01, -9.3056e-02,  4.3587e-02,  ...,  9.7284e-03,\n",
       "           -1.9213e-01, -1.2761e-02],\n",
       "          [-7.2999e-02,  4.1121e-02, -1.1946e-01,  ...,  1.1336e-01,\n",
       "           -3.0249e-02,  4.5881e-02],\n",
       "          ...,\n",
       "          [-1.6755e-01,  7.2829e-02, -1.0382e-01,  ...,  2.2103e-03,\n",
       "           -9.8529e-02, -5.5667e-02],\n",
       "          [ 3.7389e-02,  7.3607e-02, -2.8650e-02,  ...,  4.9279e-02,\n",
       "           -6.6696e-02,  8.4810e-02],\n",
       "          [-3.8462e-02, -4.6247e-02, -8.6421e-02,  ..., -6.2066e-02,\n",
       "            2.2809e-04, -7.4162e-03]],\n",
       "\n",
       "         [[ 1.5866e-02, -4.7892e-02,  3.1583e-02,  ..., -2.0716e-02,\n",
       "            4.5255e-02, -2.9508e-02],\n",
       "          [-5.0737e-03,  1.2869e-01, -7.2444e-02,  ...,  9.6547e-02,\n",
       "           -1.3206e-01, -6.0542e-02],\n",
       "          [ 3.7893e-02, -4.1217e-02,  1.3208e-02,  ..., -5.0450e-04,\n",
       "            3.6258e-02, -6.2546e-02],\n",
       "          ...,\n",
       "          [-3.9150e-02,  3.7430e-02,  1.3439e-02,  ...,  8.7309e-02,\n",
       "           -8.2993e-02,  6.1494e-02],\n",
       "          [ 1.2804e-02, -6.9906e-02,  9.6205e-02,  ...,  4.7325e-02,\n",
       "           -7.4054e-02, -8.9501e-02],\n",
       "          [-4.2714e-02,  1.2058e-01, -1.4136e-02,  ...,  7.5712e-02,\n",
       "           -5.6725e-02,  5.2051e-02]],\n",
       "\n",
       "         [[-4.8570e-02, -4.8864e-03, -1.0038e-01,  ...,  2.6428e-02,\n",
       "           -9.7755e-02,  2.3053e-02],\n",
       "          [-1.3385e-01,  1.3184e-01, -1.9972e-01,  ...,  3.7078e-02,\n",
       "           -8.9595e-03, -7.2717e-02],\n",
       "          [ 4.0139e-03,  2.1684e-03, -6.0359e-04,  ..., -1.1483e-01,\n",
       "           -1.9368e-02, -1.5312e-01],\n",
       "          ...,\n",
       "          [-7.9337e-02,  1.2092e-01, -1.0131e-01,  ...,  5.2801e-02,\n",
       "           -3.8147e-02, -3.9831e-02],\n",
       "          [ 2.6416e-02, -2.0851e-02,  4.5899e-02,  ..., -1.8830e-02,\n",
       "           -2.9850e-02, -4.5177e-02],\n",
       "          [-3.5318e-02, -1.1118e-02,  5.1035e-02,  ..., -5.7673e-02,\n",
       "            3.4070e-02, -3.3623e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.6361e-03, -1.7658e-02, -2.0112e-03,  ..., -3.3913e-02,\n",
       "           -6.3100e-02, -1.5077e-02],\n",
       "          [-9.0572e-02, -2.2174e-02,  5.0526e-02,  ..., -9.6524e-02,\n",
       "           -1.9856e-01,  9.8908e-03],\n",
       "          [-7.4909e-02,  7.7735e-02,  1.9964e-03,  ...,  1.0109e-01,\n",
       "           -9.6379e-02,  3.5598e-02],\n",
       "          ...,\n",
       "          [-1.4174e-01, -1.0948e-02, -9.6785e-02,  ..., -1.4974e-02,\n",
       "           -1.4926e-01, -1.3196e-02],\n",
       "          [-3.5684e-03, -2.3630e-02,  4.7768e-02,  ...,  2.2187e-02,\n",
       "           -1.8659e-01,  4.5777e-02],\n",
       "          [-4.0864e-02,  1.5793e-02, -4.0147e-02,  ..., -2.8221e-02,\n",
       "           -7.9413e-03, -1.6109e-02]],\n",
       "\n",
       "         [[ 1.0818e-02, -3.1856e-02,  2.8175e-02,  ...,  1.3844e-02,\n",
       "            7.9261e-02, -2.8362e-02],\n",
       "          [-5.2898e-02, -2.4845e-03, -1.3947e-01,  ...,  1.7901e-02,\n",
       "           -2.0818e-01, -2.5260e-02],\n",
       "          [ 6.2948e-02,  3.7887e-02,  1.3939e-03,  ...,  6.7750e-03,\n",
       "           -3.4731e-02, -7.9561e-02],\n",
       "          ...,\n",
       "          [-5.1947e-02, -4.1240e-04, -9.0769e-03,  ...,  1.7220e-01,\n",
       "           -1.2037e-01,  1.4419e-02],\n",
       "          [ 4.6612e-02,  5.5703e-02,  8.7191e-02,  ...,  1.1458e-02,\n",
       "            3.1620e-02, -9.6399e-02],\n",
       "          [-5.1268e-02,  9.3630e-02, -1.8376e-02,  ...,  8.9171e-02,\n",
       "           -7.3412e-02,  4.1736e-02]],\n",
       "\n",
       "         [[-5.4096e-02, -6.9906e-02, -8.4781e-02,  ..., -6.1032e-03,\n",
       "           -9.6359e-02, -2.1876e-04],\n",
       "          [-1.0752e-01,  1.4651e-01, -2.2594e-01,  ...,  4.6014e-04,\n",
       "           -4.0153e-03, -8.6446e-02],\n",
       "          [ 4.4128e-02,  1.9544e-02,  5.2606e-02,  ..., -4.6759e-02,\n",
       "           -2.0410e-02, -1.5952e-01],\n",
       "          ...,\n",
       "          [-3.4889e-02,  1.0668e-01, -2.4488e-03,  ...,  5.1110e-02,\n",
       "           -6.9363e-02, -5.4671e-02],\n",
       "          [ 7.9136e-03, -8.6937e-02,  9.3387e-02,  ..., -1.8311e-01,\n",
       "           -1.8440e-03, -4.6193e-02],\n",
       "          [-4.8631e-03,  2.2778e-03,  2.0111e-02,  ..., -6.3730e-02,\n",
       "           -4.0795e-02, -5.6816e-02]]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(netG, device, 1, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([64, 3, 64, 64]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imgs), imgs.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsnew = np.transpose(torchvision.utils.make_grid(imgs, padding=5, normalize=True).cpu(),(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([557, 557, 3]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imgsnew), imgsnew.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, dtype('float32'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imgsnew.numpy()), imgs.numpy().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels,intermediate_channels,expansion,is_Bottleneck,stride):\n",
    "        \n",
    "        \"\"\"\n",
    "        Creates a Bottleneck with conv 1x1->3x3->1x1 layers.\n",
    "        \n",
    "        Note:\n",
    "          1. Addition of feature maps occur at just before the final ReLU with the input feature maps\n",
    "          2. if input size is different from output, select projected mapping or else identity mapping.\n",
    "          3. if is_Bottleneck=False (3x3->3x3) are used else (1x1->3x3->1x1). Bottleneck is required for resnet-50/101/152\n",
    "        Args:\n",
    "            in_channels (int) : input channels to the Bottleneck\n",
    "            intermediate_channels (int) : number of channels to 3x3 conv \n",
    "            expansion (int) : factor by which the input #channels are increased\n",
    "            stride (int) : stride applied in the 3x3 conv. 2 for first Bottleneck of the block and 1 for remaining\n",
    "\n",
    "        Attributes:\n",
    "            Layer consisting of conv->batchnorm->relu\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(Bottleneck,self).__init__()\n",
    "\n",
    "        self.expansion = expansion\n",
    "        self.in_channels = in_channels\n",
    "        self.intermediate_channels = intermediate_channels\n",
    "        self.is_Bottleneck = is_Bottleneck\n",
    "        \n",
    "        # i.e. if dim(x) == dim(F) => Identity function\n",
    "        if self.in_channels==self.intermediate_channels*self.expansion:\n",
    "            self.identity = True\n",
    "        else:\n",
    "            self.identity = False\n",
    "            projection_layer = []\n",
    "            projection_layer.append(nn.Conv2d(in_channels=self.in_channels, out_channels=self.intermediate_channels*self.expansion, kernel_size=1, stride=stride, padding=0, bias=False ))\n",
    "            projection_layer.append(nn.BatchNorm2d(self.intermediate_channels*self.expansion))\n",
    "            # Only conv->BN and no ReLU\n",
    "            # projection_layer.append(nn.ReLU())\n",
    "            self.projection = nn.Sequential(*projection_layer)\n",
    "\n",
    "        # commonly used relu\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # is_Bottleneck = True for all ResNet 50+\n",
    "        if self.is_Bottleneck:\n",
    "            # bottleneck\n",
    "            # 1x1\n",
    "            self.conv1_1x1 = nn.Conv2d(in_channels=self.in_channels, out_channels=self.intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False )\n",
    "            self.batchnorm1 = nn.BatchNorm2d(self.intermediate_channels)\n",
    "            \n",
    "            # 3x3\n",
    "            self.conv2_3x3 = nn.Conv2d(in_channels=self.intermediate_channels, out_channels=self.intermediate_channels, kernel_size=3, stride=stride, padding=1, bias=False )\n",
    "            self.batchnorm2 = nn.BatchNorm2d(self.intermediate_channels)\n",
    "            \n",
    "            # 1x1\n",
    "            self.conv3_1x1 = nn.Conv2d(in_channels=self.intermediate_channels, out_channels=self.intermediate_channels*self.expansion, kernel_size=1, stride=1, padding=0, bias=False )\n",
    "            self.batchnorm3 = nn.BatchNorm2d( self.intermediate_channels*self.expansion )\n",
    "        \n",
    "        else:\n",
    "            # basicblock\n",
    "            # 3x3\n",
    "            self.conv1_3x3 = nn.Conv2d(in_channels=self.in_channels, out_channels=self.intermediate_channels, kernel_size=3, stride=stride, padding=1, bias=False )\n",
    "            self.batchnorm1 = nn.BatchNorm2d(self.intermediate_channels)\n",
    "            \n",
    "            # 3x3\n",
    "            self.conv2_3x3 = nn.Conv2d(in_channels=self.intermediate_channels, out_channels=self.intermediate_channels, kernel_size=3, stride=1, padding=1, bias=False )\n",
    "            self.batchnorm2 = nn.BatchNorm2d(self.intermediate_channels)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # input stored to be added before the final relu\n",
    "        in_x = x\n",
    "\n",
    "        if self.is_Bottleneck:\n",
    "            # conv1x1->BN->relu\n",
    "            x = self.relu(self.batchnorm1(self.conv1_1x1(x)))\n",
    "            \n",
    "            # conv3x3->BN->relu\n",
    "            x = self.relu(self.batchnorm2(self.conv2_3x3(x)))\n",
    "            \n",
    "            # conv1x1->BN\n",
    "            x = self.batchnorm3(self.conv3_1x1(x))\n",
    "        \n",
    "        else:\n",
    "            # conv3x3->BN->relu\n",
    "            x = self.relu(self.batchnorm1(self.conv1_3x3(x)))\n",
    "\n",
    "            # conv3x3->BN\n",
    "            x = self.batchnorm2(self.conv2_3x3(x))\n",
    "\n",
    "\n",
    "        # identity or projected mapping\n",
    "        if self.identity:\n",
    "            x += in_x\n",
    "        else:\n",
    "            x += self.projection(in_x)\n",
    "\n",
    "        # final relu\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Bottleneck(64*4,64,4,stride=1)\n",
    "\n",
    "def test_Bottleneck():\n",
    "    x = torch.randn(1,64,112,112)\n",
    "    model = Bottleneck(64,64,4,True,2)\n",
    "    print(model(x).shape)\n",
    "    del model\n",
    "\n",
    "test_Bottleneck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, resnet_variant,in_channels,num_classes):\n",
    "        \"\"\"\n",
    "        Creates the ResNet architecture based on the provided variant. 18/34/50/101 etc.\n",
    "        Based on the input parameters, define the channels list, repeatition list along with expansion factor(4) and stride(3/1)\n",
    "        using _make_blocks method, create a sequence of multiple Bottlenecks\n",
    "        Average Pool at the end before the FC layer \n",
    "\n",
    "        Args:\n",
    "            resnet_variant (list) : eg. [[64,128,256,512],[3,4,6,3],4,True]\n",
    "            in_channels (int) : image channels (3)\n",
    "            num_classes (int) : output #classes \n",
    "\n",
    "        Attributes:\n",
    "            Layer consisting of conv->batchnorm->relu\n",
    "\n",
    "        \"\"\"\n",
    "        super(ResNet,self).__init__()\n",
    "        self.channels_list = resnet_variant[0]\n",
    "        self.repeatition_list = resnet_variant[1]\n",
    "        self.expansion = resnet_variant[2]\n",
    "        self.is_Bottleneck = resnet_variant[3]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False )\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "        # self.block1 = self._make_blocks( 64 , self.channels_list[0], self.repeatition_list[0], self.expansion, self.is_Bottleneck, stride=1 )\n",
    "        self.block1 = nn.Sequential(*[\n",
    "            Bottleneck(64,self.channels_list[0],self.expansion,self.is_Bottleneck,stride=1),\n",
    "            Bottleneck(self.channels_list[0] * self.expansion,self.channels_list[0],self.expansion,self.is_Bottleneck,stride=1),\n",
    "            Bottleneck(self.channels_list[0] * self.expansion,self.channels_list[0],self.expansion,self.is_Bottleneck,stride=1),\n",
    "        ])\n",
    "\n",
    "        # self.block2 = self._make_blocks( self.channels_list[0]*self.expansion , self.channels_list[1], self.repeatition_list[1], self.expansion, self.is_Bottleneck, stride=2 )\n",
    "        self.block2 = nn.Sequential(*[\n",
    "            Bottleneck(self.channels_list[0] * self.expansion,self.channels_list[1],self.expansion,self.is_Bottleneck,stride=2),\n",
    "            Bottleneck(self.channels_list[1] * self.expansion,self.channels_list[1],self.expansion,self.is_Bottleneck,stride=1),\n",
    "            Bottleneck(self.channels_list[1] * self.expansion,self.channels_list[1],self.expansion,self.is_Bottleneck,stride=1),\n",
    "            Bottleneck(self.channels_list[1] * self.expansion,self.channels_list[1],self.expansion,self.is_Bottleneck,stride=1),\n",
    "        ])\n",
    "\n",
    "        # self.block3 = self._make_blocks( self.channels_list[1]*self.expansion , self.channels_list[2], self.repeatition_list[2], self.expansion, self.is_Bottleneck, stride=2 )\n",
    "        self.block3 = nn.Sequential(*[\n",
    "            Bottleneck(self.channels_list[1] * self.expansion,self.channels_list[2],self.expansion,self.is_Bottleneck,stride=2),\n",
    "            Bottleneck(self.channels_list[2] * self.expansion,self.channels_list[2],self.expansion,self.is_Bottleneck,stride=1),\n",
    "            Bottleneck(self.channels_list[2] * self.expansion,self.channels_list[2],self.expansion,self.is_Bottleneck,stride=1),\n",
    "            Bottleneck(self.channels_list[2] * self.expansion,self.channels_list[2],self.expansion,self.is_Bottleneck,stride=1),\n",
    "            Bottleneck(self.channels_list[2] * self.expansion,self.channels_list[2],self.expansion,self.is_Bottleneck,stride=1),\n",
    "            Bottleneck(self.channels_list[2] * self.expansion,self.channels_list[2],self.expansion,self.is_Bottleneck,stride=1),\n",
    "        ])\n",
    "\n",
    "        # self.block4 = self._make_blocks( self.channels_list[2]*self.expansion , self.channels_list[3], self.repeatition_list[3], self.expansion, self.is_Bottleneck, stride=2 )\n",
    "        self.block4 = nn.Sequential(*[\n",
    "            Bottleneck(self.channels_list[2] * self.expansion,self.channels_list[3],self.expansion,self.is_Bottleneck,stride=2),\n",
    "            Bottleneck(self.channels_list[3] * self.expansion,self.channels_list[3],self.expansion,self.is_Bottleneck,stride=1),\n",
    "            Bottleneck(self.channels_list[3] * self.expansion,self.channels_list[3],self.expansion,self.is_Bottleneck,stride=1),\n",
    "        ])\n",
    "\n",
    "        self.average_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear( self.channels_list[3]*self.expansion , num_classes)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.batchnorm1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        \n",
    "        x = self.block2(x)\n",
    "        \n",
    "        x = self.block3(x)\n",
    "        \n",
    "        x = self.block4(x)\n",
    "        \n",
    "        x = self.average_pool(x)\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def _make_blocks(self,in_channels,intermediate_channels,num_repeat, expansion, is_Bottleneck, stride):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels : #channels of the Bottleneck input\n",
    "            intermediate_channels : #channels of the 3x3 in the Bottleneck\n",
    "            num_repeat : #Bottlenecks in the block\n",
    "            expansion : factor by which intermediate_channels are multiplied to create the output channels\n",
    "            is_Bottleneck : status if Bottleneck in required\n",
    "            stride : stride to be used in the first Bottleneck conv 3x3\n",
    "\n",
    "        Attributes:\n",
    "            Sequence of Bottleneck layers\n",
    "\n",
    "        \"\"\"\n",
    "        layers = [] \n",
    "\n",
    "        layers.append(Bottleneck(in_channels,intermediate_channels,expansion,is_Bottleneck,stride=stride))\n",
    "        for num in range(1,num_repeat):\n",
    "            layers.append(Bottleneck(intermediate_channels*expansion,intermediate_channels,expansion,is_Bottleneck,stride=1))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def test_ResNet(params):\n",
    "    model = ResNet( params , in_channels=3, num_classes=1000)\n",
    "    x = torch.randn(1,3,224,224)\n",
    "    output = model(x)\n",
    "    print(output.shape)\n",
    "    return model\n",
    "\n",
    "\n",
    "model_parameters={}\n",
    "model_parameters['resnet18'] = ([64,128,256,512],[2,2,2,2],1,False)\n",
    "model_parameters['resnet34'] = ([64,128,256,512],[3,4,6,3],1,False)\n",
    "model_parameters['resnet50'] = ([64,128,256,512],[3,4,6,3],4,True)\n",
    "model_parameters['resnet101'] = ([64,128,256,512],[3,4,23,3],4,True)\n",
    "model_parameters['resnet152'] = ([64,128,256,512],[3,8,36,3],4,True)\n",
    "\n",
    "architecture = 'resnet50'\n",
    "model = test_ResNet(model_parameters[architecture])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 800]         628,000\n",
      "            Linear-2                   [-1, 10]           8,010\n",
      "================================================================\n",
      "Total params: 636,010\n",
      "Trainable params: 636,010\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 2.43\n",
      "Estimated Total Size (MB): 2.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class FCNet(nn.Module):\n",
    "\t\n",
    "\tdef __init__(self, layers=[784, 800, 10]):\n",
    "\t\tsuper(FCNet, self).__init__()\n",
    "\t\tself.layers = nn.ModuleList([nn.Linear(a, b) for a, b in zip(layers[:-1], layers[1:])])\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tfor layer in self.layers[:-1]:\n",
    "\t\t\tx = F.relu(layer(x))\n",
    "\t\tx = self.layers[-1](x)\n",
    "\t\treturn F.log_softmax(x, dim=1)\n",
    "\n",
    "train_dl, _, _ = get_mnist_loaders(128)\n",
    "input_size = next(iter(train_dl))[0].shape[1:]\n",
    "\n",
    "fcnet = FCNet()\n",
    "fcnet = fcnet.to(device)\n",
    "summary(fcnet, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             416\n",
      "              ReLU-2           [-1, 16, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 16, 14, 14]               0\n",
      "            Conv2d-4           [-1, 32, 14, 14]          12,832\n",
      "              ReLU-5           [-1, 32, 14, 14]               0\n",
      "         MaxPool2d-6             [-1, 32, 7, 7]               0\n",
      "            Linear-7                  [-1, 500]         784,500\n",
      "            Linear-8                   [-1, 10]           5,010\n",
      "================================================================\n",
      "Total params: 802,758\n",
      "Trainable params: 802,758\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.33\n",
      "Params size (MB): 3.06\n",
      "Estimated Total Size (MB): 3.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class SCVNet(nn.Module):\n",
    "\n",
    "\tdef __init__(self, num_classes=10):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.conv1 = nn.Sequential(         \n",
    "\t\t\tnn.Conv2d(1, 16, 5, 1, 2),\n",
    "\t\t\tnn.ReLU(),                                       \n",
    "\t\t\tnn.MaxPool2d(2)\n",
    "\t\t)\n",
    "\t\tself.conv2 = nn.Sequential(         \n",
    "\t\t\tnn.Conv2d(16, 32, 5, 1, 2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(2),  \n",
    "\t\t)\n",
    "\t\tself.dense = nn.Linear(32 * 7 * 7, 500)\n",
    "\t\tself.classifier = nn.Linear(500, num_classes)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = torch.flatten(x, 1)\n",
    "\t\tx = F.relu(self.dense(x))\n",
    "\t\treturn F.log_softmax(self.classifier(x), dim=1)\n",
    "\t\n",
    "train_dl, _, _ = get_mnist_loaders(128, flatten=False)\n",
    "input_size = next(iter(train_dl))[0].shape[1:]\n",
    "print(input_size)\n",
    "\n",
    "scvnet = SCVNet()\n",
    "scvnet = scvnet.to(device)\n",
    "summary(scvnet, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 512, 4, 4]         819,200\n",
      "       BatchNorm2d-2            [-1, 512, 4, 4]           1,024\n",
      "              ReLU-3            [-1, 512, 4, 4]               0\n",
      "   ConvTranspose2d-4            [-1, 256, 8, 8]       2,097,152\n",
      "       BatchNorm2d-5            [-1, 256, 8, 8]             512\n",
      "              ReLU-6            [-1, 256, 8, 8]               0\n",
      "   ConvTranspose2d-7          [-1, 128, 16, 16]         524,288\n",
      "       BatchNorm2d-8          [-1, 128, 16, 16]             256\n",
      "              ReLU-9          [-1, 128, 16, 16]               0\n",
      "  ConvTranspose2d-10           [-1, 64, 32, 32]         131,072\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "             ReLU-12           [-1, 64, 32, 32]               0\n",
      "  ConvTranspose2d-13            [-1, 3, 64, 64]           3,072\n",
      "             Tanh-14            [-1, 3, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 3,576,704\n",
      "Trainable params: 3,576,704\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.00\n",
      "Params size (MB): 13.64\n",
      "Estimated Total Size (MB): 16.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gen = Generator(3, 100, 64)\n",
    "gen = gen.to(device)\n",
    "summary(gen, (100, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           3,072\n",
      "         LeakyReLU-2           [-1, 64, 32, 32]               0\n",
      "            Conv2d-3          [-1, 128, 16, 16]         131,072\n",
      "       BatchNorm2d-4          [-1, 128, 16, 16]             256\n",
      "         LeakyReLU-5          [-1, 128, 16, 16]               0\n",
      "            Conv2d-6            [-1, 256, 8, 8]         524,288\n",
      "       BatchNorm2d-7            [-1, 256, 8, 8]             512\n",
      "         LeakyReLU-8            [-1, 256, 8, 8]               0\n",
      "            Conv2d-9            [-1, 512, 4, 4]       2,097,152\n",
      "      BatchNorm2d-10            [-1, 512, 4, 4]           1,024\n",
      "        LeakyReLU-11            [-1, 512, 4, 4]               0\n",
      "           Conv2d-12              [-1, 1, 1, 1]           8,192\n",
      "          Sigmoid-13              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 2,765,568\n",
      "Trainable params: 2,765,568\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.31\n",
      "Params size (MB): 10.55\n",
      "Estimated Total Size (MB): 12.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "disc = Discriminator(3, 64)\n",
    "disc = disc.to(device)\n",
    "summary(disc, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 64, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_noise = torch.randn(32, 100, 1, 1, device=device)\n",
    "print(fixed_noise.shape)\n",
    "gen(fixed_noise).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 23,528,522\n",
      "Trainable params: 23,528,522\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.86\n",
      "Params size (MB): 89.75\n",
      "Estimated Total Size (MB): 95.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rn = resnet50()\n",
    "rn.fc = nn.Linear(in_features=2048, out_features=num_classes, bias=True)\n",
    "rn = rn.to(device)\n",
    "train_dl, _ = get_cifar10_loaders(128)\n",
    "input_size = next(iter(train_dl))[0].shape[1:]\n",
    "\n",
    "summary(rn, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 23,528,522\n",
      "Trainable params: 23,528,522\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.86\n",
      "Params size (MB): 89.75\n",
      "Estimated Total Size (MB): 95.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rn_native = ResNet(model_parameters['resnet50'], in_channels=3, num_classes=10)\n",
    "rn_native = rn_native.to(device)\n",
    "train_dl, _ = get_cifar10_loaders(128)\n",
    "input_size = next(iter(train_dl))[0].shape[1:]\n",
    "\n",
    "summary(rn_native, input_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
