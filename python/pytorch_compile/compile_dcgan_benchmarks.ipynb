{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1kmFKQ485DKpxPp88NtyXA5fp8KZD1oHo","authorship_tag":"ABX9TyNtv0oxJgEhH2ViKKXqk6fV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"0zi0bbEo5VB5","executionInfo":{"status":"ok","timestamp":1714085419642,"user_tz":-120,"elapsed":9165,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision.models import resnet50, densenet121, mobilenet_v2, convnext_tiny\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision\n","import matplotlib.pyplot as plt\n","import torch._dynamo\n","from collections import defaultdict\n","from functools import reduce"]},{"cell_type":"code","source":["def get_celeba_loader(batch_size, image_size=64, root='./drive/MyDrive/colab/datasets/celeba'):\n","    transform = torchvision.transforms.Compose([\n","        torchvision.transforms.Resize(image_size),\n","        torchvision.transforms.CenterCrop(image_size),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","    ])\n","\n","    ds = torchvision.datasets.ImageFolder(root=root, transform=transform)\n","    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","    return dl\n","\n","\n","def get_celeba_loader_from_memory(batch_size, image_size=64, root='./drive/MyDrive/colab/datasets/celeba'):\n","\tdl = get_celeba_loader(batch_size, image_size=image_size, root=root)\n","\tcollected_batches = [batch for batch in dl]\n","\treturn collected_batches\n","\n","\n","def fit_dcgan_step(generator, discriminator, device, real, loss_func, optimizerG, optimizerD, latent_vec_size):\n","  real_label = 1.\n","  fake_label = 0.\n","\n","  discriminator.zero_grad()\n","  b_size = real.size(0)\n","  label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","  output = discriminator(real).view(-1)\n","  errD_real = loss_func(output, label)\n","  errD_real.backward()\n","  D_x = output.mean().item()\n","\n","  noise = torch.randn(b_size, latent_vec_size, 1, 1, device=device)\n","  fake = generator(noise)\n","  label.fill_(fake_label)\n","  output = discriminator(fake.detach()).view(-1)\n","  errD_fake = loss_func(output, label)\n","  errD_fake.backward()\n","  D_G_z1 = output.mean().item()\n","  errD = errD_real + errD_fake\n","  optimizerD.step()\n","\n","  generator.zero_grad()\n","  label.fill_(real_label)\n","  output = discriminator(fake).view(-1)\n","  errG = loss_func(output, label)\n","  errG.backward()\n","  D_G_z2 = output.mean().item()\n","  optimizerG.step()\n","\n","  return [errG.item(), errD.item(), D_x, D_G_z1, D_G_z2]\n","\n","\n","def dcgan_weights_init(model):\n","  classname = model.__class__.__name__\n","  if classname.find('Conv') != -1:\n","      nn.init.normal_(model.weight.data, 0.0, 0.02)\n","  elif classname.find('BatchNorm') != -1:\n","      nn.init.normal_(model.weight.data, 1.0, 0.02)\n","      nn.init.constant_(model.bias.data, 0)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, n_channels, latent_vec_size, feat_map_size):\n","        super(Generator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d(latent_vec_size, feat_map_size * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 8),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(feat_map_size * 8, feat_map_size * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 4),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(feat_map_size * 4, feat_map_size * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 2),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(feat_map_size * 2, feat_map_size, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(feat_map_size, n_channels, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, n_channels, feat_map_size):\n","        super(Discriminator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(n_channels, feat_map_size, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(feat_map_size, feat_map_size * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(feat_map_size * 2, feat_map_size * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(feat_map_size * 4, feat_map_size * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(feat_map_size * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(feat_map_size * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","\n","def latency(model, sample):\n","\tstart = torch.cuda.Event(enable_timing=True)\n","\tend = torch.cuda.Event(enable_timing=True)\n","\tstart.record()\n","\t_ = model(sample)\n","\tend.record()\n","\ttorch.cuda.synchronize()\n","\treturn start.elapsed_time(end)"],"metadata":{"id":"XEYngN0ZggCO","executionInfo":{"status":"ok","timestamp":1714087658974,"user_tz":-120,"elapsed":3,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    print('device count:', torch.cuda.device_count())\n","    device = torch.device(0)\n","    device_cap = torch.cuda.get_device_capability()\n","    print(f\"GPU {torch.cuda.get_device_name(0)} available with compatibility {device_cap}\")\n","    if device_cap not in ((7, 0), (8, 0), (9, 0)):\n","        print(\"GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU unavailable\")"],"metadata":{"id":"Rb9RxCDutv1r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714085419644,"user_tz":-120,"elapsed":8,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"bcc73236-934b-44aa-f11e-492c3d1c0b7f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["device count: 1\n","GPU Tesla T4 available with compatibility (7, 5)\n","GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\n"]}]},{"cell_type":"code","source":["nc = 3\n","nz = 100\n","ngf = 64\n","ndf = 64\n","latent_vec_size = 100\n","\n","batch_size = 96\n","lr = 1e-4\n","gen_batch_size = 1024\n","epochs = 2\n","log_interval = 200\n","timestamp = time.time_ns()\n","results_eager_filepath = f'./drive/MyDrive/colab/results/pytorch-dcgan-eager-{timestamp}.csv'\n","results_compile_filepath = f'./drive/MyDrive/colab/results/pytorch-dcgan-compile-{timestamp}.csv'\n","start = torch.cuda.Event(enable_timing=True)\n","end = torch.cuda.Event(enable_timing=True)"],"metadata":{"id":"YvEVZMN7twlI","executionInfo":{"status":"ok","timestamp":1714085419644,"user_tz":-120,"elapsed":5,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["celeba_dl = get_celeba_loader_from_memory(batch_size=batch_size, root='./drive/MyDrive/colab/datasets/celeba_tiny')\n","# takes a loooot of time thus separate code block"],"metadata":{"id":"Dr6wxDPRvGZc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714086256480,"user_tz":-120,"elapsed":582497,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"9ca0b7b0-7d2e-4d98-ff20-bf86aeabf52c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]}]},{"cell_type":"markdown","source":["## Training - eager mode"],"metadata":{"id":"Bw58hMDvvjAB"}},{"cell_type":"code","source":["telemetry_eager = defaultdict(list)\n","\n","netG = Generator(nc, nz, ngf).to(device)\n","netD = Discriminator(nc, ndf).to(device)\n","netG.apply(dcgan_weights_init)\n","netD.apply(dcgan_weights_init)\n","netG.train()\n","netD.train()\n","\n","loss_func = nn.BCELoss()\n","optG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n","optD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n","\n","for epoch in range(1, epochs + 1):\n","  running_stats = [0 for _ in range(5)]\n","  start.record()\n","  for xb in celeba_dl:\n","    xb = xb[0].to(device)\n","    stats = fit_dcgan_step(netG, netD, device, xb, loss_func, optG, optD, latent_vec_size)\n","\n","    for i, stat in enumerate(stats):\n","      running_stats[i] += stat\n","  end.record()\n","  torch.cuda.synchronize()\n","\n","  for i, stat in enumerate(running_stats):\n","    running_stats[i] = stat / len(celeba_dl)\n","\n","  telemetry_eager['model_name'].append('DCGAN')\n","  telemetry_eager['phase'].append('training')\n","  telemetry_eager['epoch'].append(epoch)\n","  telemetry_eager['loss'].append(f'{running_stats[0]}|{running_stats[1]}')\n","  telemetry_eager['performance'].append(f'{running_stats[2]}|{running_stats[3]}|{running_stats[4]}')\n","  telemetry_eager['elapsed_time'].append(start.elapsed_time(end) * 1e6)\n","  pd.DataFrame(telemetry_eager).to_csv(results_eager_filepath, index=False)\n","  print(f'Epoch {epoch} finished with execution time of {start.elapsed_time(end) / 1e3}s')"],"metadata":{"id":"6SnSrEJtvpna","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714088280588,"user_tz":-120,"elapsed":47491,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"54462d61-be6a-441b-d161-3243a8a24a59"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 finished with execution time of 22.94624609375s\n","Epoch 2 finished with execution time of 23.364908203125s\n"]}]},{"cell_type":"markdown","source":["## Latency - both modes"],"metadata":{"id":"ChAvRyPVmUJn"}},{"cell_type":"code","source":["telemetry_compile = defaultdict(list)"],"metadata":{"id":"WayJkDR1VW_g","executionInfo":{"status":"ok","timestamp":1714088326847,"user_tz":-120,"elapsed":424,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["warmup = 10\n","netG = Generator(nc, nz, ngf).to(device)\n","netG.apply(dcgan_weights_init)\n","torch._dynamo.reset()\n","netG_comp = torch.compile(netG, mode='reduce-overhead')\n","netG.eval()\n","\n","latent_vecs = torch.randn(epochs + warmup + 1, latent_vec_size, 1, 1, device=device)\n","# latent_vecs[0].unsqueeze(0).size()\n","\n","telemetry_eager_times = []\n","telemetry_compile_times = []\n","\n","# compilation\n","with torch.no_grad():\n","  e = latency(netG, latent_vecs[-1].unsqueeze(0))\n","  print('compilation - eager mode:', e)\n","  telemetry_eager_times.append(e)\n","\n","  c = latency(netG_comp, latent_vecs[-1].unsqueeze(0))\n","  print('compilation - compile mode:', c)\n","  telemetry_compile_times.append(c)\n","\n","  for i in range(epochs + warmup):\n","    # warmup\n","    e = latency(netG, latent_vecs[1].unsqueeze(0))\n","    c = latency(netG_comp, latent_vecs[i].unsqueeze(0))\n","\n","    # latency\n","    if i >= warmup:\n","        telemetry_eager_times.append(e)\n","        telemetry_compile_times.append(c)\n","\n","em = np.median(telemetry_eager_times)\n","cm = np.median(telemetry_compile_times)\n","print(f'median exec time (e/c): {em} / {cm}')\n","print(f'compiled graph is on average {em / cm} times faster than eager execution')\n","\n","\n","# telemetry\n","for telemetry, telemetry_times in [(telemetry_eager, telemetry_eager_times),\n","                                   (telemetry_compile, telemetry_compile_times)]:\n","  telemetry['model_name'].extend([\"DCGAN\"] * (epochs + 1))\n","  telemetry['phase'].extend(['graph_compilation'] + ['latency'] * epochs)\n","  telemetry['epoch'].extend([1] + list(range(1, epochs + 1)))\n","  telemetry['loss'].extend([-1] * (epochs + 1))\n","  telemetry['performance'].extend([-1] * (epochs + 1))\n","  telemetry['elapsed_time'].extend(telemetry_times)\n","\n","pd.DataFrame(telemetry_compile).to_csv(results_compile_filepath, index=False)\n","pd.DataFrame(telemetry_eager).to_csv(results_eager_filepath, index=False)"],"metadata":{"id":"ceMklhYHmV6p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714088334443,"user_tz":-120,"elapsed":2580,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"cc1231ef-8a69-4cc9-ad89-9649d346430a"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["compilation - eager mode: 0.8944960236549377\n","compilation - compile mode: 950.4771728515625\n","median exec time (e/c): 0.6674559712409973 / 1.007423996925354\n","compiled graph is on average 0.6625372963896681 times faster than eager execution\n","model_name 3\n","phase 3\n","epoch 3\n","loss 3\n","performance 3\n","elapsed_time 3\n"]}]},{"cell_type":"markdown","source":["## Latency on batch - both modes"],"metadata":{"id":"VJy-ZEihX2IR"}},{"cell_type":"code","source":["warmup = 50\n","netG = Generator(nc, nz, ngf).to(device)\n","netG.apply(dcgan_weights_init)\n","torch._dynamo.reset()\n","netG_comp = torch.compile(netG, mode='reduce-overhead')\n","netG.eval()\n","\n","telemetry_eager_times = []\n","telemetry_compile_times = []\n","\n","# compilation\n","with torch.no_grad():\n","  latent_vec = torch.randn(1024, latent_vec_size, 1, 1, device=device)\n","  e = latency(netG, latent_vecs)\n","  print('compilation - eager mode:', e)\n","  telemetry_eager_times.append(e)\n","\n","  c = latency(netG_comp, latent_vec)\n","  print('compilation - compile mode:', c)\n","  telemetry_compile_times.append(c)\n","\n","  for i in range(epochs + warmup):\n","    latent_vec = torch.randn(1024, latent_vec_size, 1, 1, device=device)\n","    # warmup\n","    e = latency(netG, latent_vec)\n","    c = latency(netG_comp, latent_vec)\n","\n","    # latency\n","    if i >= warmup:\n","        telemetry_eager_times.append(e)\n","        telemetry_compile_times.append(c)\n","\n","em = np.median(telemetry_eager_times)\n","cm = np.median(telemetry_compile_times)\n","print(f'median exec time (e/c): {em} / {cm}')\n","print(f'compiled graph is on average {em / cm} times faster than eager execution')\n","\n","\n","# telemetry\n","for telemetry, telemetry_times in [(telemetry_eager, telemetry_eager_times),\n","                                   (telemetry_compile, telemetry_compile_times)]:\n","  telemetry['model_name'].extend([\"DCGAN\"] * (epochs + 1))\n","  telemetry['phase'].extend(['graph_compilation_batch'] + ['latency_batch'] * epochs)\n","  telemetry['epoch'].extend([1] + list(range(1, epochs + 1)))\n","  telemetry['loss'].extend([-1] * (epochs + 1))\n","  telemetry['performance'].extend([-1] * (epochs + 1))\n","  telemetry['elapsed_time'].extend(telemetry_times)\n","\n","pd.DataFrame(telemetry_compile).to_csv(results_compile_filepath, index=False)\n","pd.DataFrame(telemetry_eager).to_csv(results_eager_filepath, index=False)"],"metadata":{"id":"pXm3GVvqSLAY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714088457794,"user_tz":-120,"elapsed":19056,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"e7b31007-9a1a-440d-8e07-873c1a74c861"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["compilation - eager mode: 5.798272132873535\n","compilation - compile mode: 1588.83837890625\n","median exec time (e/c): 159.6262969970703 / 163.96524047851562\n","compiled graph is on average 0.9735374188530291 times faster than eager execution\n"]}]},{"cell_type":"markdown","source":["## Training - compile mode"],"metadata":{"id":"2Dx0OZtnb5-6"}},{"cell_type":"code","source":["netG = Generator(nc, nz, ngf).to(device)\n","netD = Discriminator(nc, ndf).to(device)\n","netG.apply(dcgan_weights_init)\n","netD.apply(dcgan_weights_init)\n","torch._dynamo.reset()\n","netG = torch.compile(netG, mode='reduce-overhead')\n","netD = torch.compile(netD, mode='reduce-overhead')\n","netG.train()\n","netD.train()\n","\n","loss_func = nn.BCELoss()\n","optG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n","optD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n","\n","fit_dcgan_step_compiled = torch.compile(fit_dcgan_step, mode=\"reduce-overhead\")\n","\n","for epoch in range(1, epochs + 1):\n","  running_stats = [0 for _ in range(5)]\n","  start.record()\n","  for xb in celeba_dl:\n","    xb = xb[0].to(device)\n","    stats = fit_dcgan_step_compiled(netG, netD, device, xb, loss_func, optG, optD, latent_vec_size)\n","\n","    for i, stat in enumerate(stats):\n","      running_stats[i] += stat\n","  end.record()\n","  torch.cuda.synchronize()\n","\n","  for i, stat in enumerate(running_stats):\n","    running_stats[i] = stat / len(celeba_dl)\n","\n","  telemetry_compile['model_name'].append('DCGAN')\n","  telemetry_compile['phase'].append('training')\n","  telemetry_compile['epoch'].append(epoch)\n","  telemetry_compile['loss'].append(f'{running_stats[0]}|{running_stats[1]}')\n","  telemetry_compile['performance'].append(f'{running_stats[2]}|{running_stats[3]}|{running_stats[4]}')\n","  telemetry_compile['elapsed_time'].append(start.elapsed_time(end) * 1e6)\n","  pd.DataFrame(telemetry_compile).to_csv(results_compile_filepath, index=False)\n","  print(f'Epoch {epoch} finished with execution time of {start.elapsed_time(end) / 1e3}s')"],"metadata":{"id":"bu0T2rszb47L"},"execution_count":null,"outputs":[]}]}