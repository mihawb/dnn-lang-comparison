{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1eVhcMxYGh0I9NYMYiHlb8RWJBDBcsO-u","authorship_tag":"ABX9TyNtVfHJVm8SL1qAGQQuF83+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"zv0nIWjsLAlr","executionInfo":{"status":"ok","timestamp":1714085193162,"user_tz":-120,"elapsed":265,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision.models import resnet50, densenet121, mobilenet_v2, convnext_tiny\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision\n","import matplotlib.pyplot as plt\n","import torch._dynamo\n","from collections import defaultdict\n","from functools import reduce"]},{"cell_type":"markdown","source":[],"metadata":{"id":"Z1iqTJfQHUJX"}},{"cell_type":"code","source":["def load_mnist_imgs_and_labels(imgs_path, labels_path) -> tuple[np.ndarray, np.ndarray]:\n","\ti_hand = open(imgs_path, 'rb')\n","\tl_hand = open(labels_path, 'rb')\n","\n","\ti_hand.seek(4, 0) # skipping \"magic\" numbers\n","\tl_hand.seek(4, 0)\n","\n","\tn_imgs = int.from_bytes(i_hand.read(4), 'big')\n","\n","\timgs = np.frombuffer(i_hand.read(), np.uint8, offset=8)\n","\timgs = (255 - imgs) / 255\n","\timgs = imgs.reshape(n_imgs, 28 * 28)\n","\n","\tlabels = np.frombuffer(l_hand.read(), np.uint8, offset=4)\n","\n","\ti_hand.close()\n","\tl_hand.close()\n","\n","\treturn imgs, labels\n","\n","\n","def get_mnist_loaders(batch_size, test_batch_size=None, cutoff=1, flatten=True):\n","\tif test_batch_size is None: test_batch_size = batch_size * 2\n","\n","\tx_train, y_train = load_mnist_imgs_and_labels(\n","\t\t'./drive/MyDrive/colab/datasets/mnist-digits/train-images-idx3-ubyte',\n","\t\t'./drive/MyDrive/colab/datasets/mnist-digits/train-labels-idx1-ubyte'\n","\t)\n","\n","\tx_train, x_val = np.split(x_train, [int(len(x_train) * cutoff)])\n","\ty_train, y_val = np.split(y_train, [int(len(y_train) * cutoff)])\n","\n","\tx_test, y_test = load_mnist_imgs_and_labels(\n","\t\t'./drive/MyDrive/colab/datasets/mnist-digits/t10k-images-idx3-ubyte',\n","\t\t'./drive/MyDrive/colab/datasets/mnist-digits/t10k-labels-idx1-ubyte'\n","\t)\n","\n","\tif not flatten:\n","\t\tx_train, x_test = map(\n","\t\t\tlambda x: x.reshape(-1, 1, 28, 28),\n","\t\t\t(x_train, x_test)\n","\t\t)\n","\n","\tx_train, y_train, x_val, y_val, x_test, y_test = map(\n","\t\ttorch.tensor,\n","\t\t(x_train, y_train, x_val, y_val, x_test, y_test)\n","\t)\n","\n","\tx_train, x_val, x_test = map(\n","\t\tlambda x: x.to(torch.float32),\n","\t\t(x_train, x_val, x_test)\n","\t)\n","\n","\ty_train, y_val, y_test = map(\n","\t\t\tlambda y: y.to(torch.int64),\n","\t\t\t(y_train, y_val, y_test)\n","\t\t)\n","\n","\ttrain_ds = TensorDataset(x_train, y_train)\n","\tval_ds = TensorDataset(x_val, y_val)\n","\ttest_ds = TensorDataset(x_test, y_test)\n","\n","\ttrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","\tval_dl = DataLoader(val_ds, batch_size=test_batch_size)\n","\ttest_dl = DataLoader(test_ds, batch_size=test_batch_size)\n","\n","\treturn train_dl, val_dl, test_dl\n","\n","\n","def get_cifar10_loaders(batch_size, test_batch_size=None, image_size=32):\n","\tif test_batch_size is None: test_batch_size = batch_size * 2\n","\n","\ttransform = torchvision.transforms.Compose([\n","\t\ttorchvision.transforms.Resize(image_size),\n","\t\ttorchvision.transforms.ToTensor(),\n","\t\ttorchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","\t])\n","\n","\ttrain_ds = torchvision.datasets.CIFAR10(root='./drive/MyDrive/colab/datasets/cifar-10-py/', train=True, download=True, transform=transform)\n","\ttest_ds = torchvision.datasets.CIFAR10(root='./drive/MyDrive/colab/datasets/cifar-10-py/', train=False, download=True, transform=transform)\n","\n","\ttrain_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n","\ttest_dl = torch.utils.data.DataLoader(test_ds, batch_size=test_batch_size, shuffle=False, num_workers=2, drop_last=True)\n","\n","\treturn train_dl, test_dl\n","\n","\n","def fit_step(model, xb, yb, loss_func, optimizer):\n","\toptimizer.zero_grad()\n","\tpred = model(xb)\n","\tloss = loss_func(pred, yb)\n","\tloss.backward()\n","\toptimizer.step()\n","\treturn loss.item()\n","\n","\n","def test_step(model, xb, yb, loss_func):\n","\tpred = model(xb)\n","\ttest_loss = loss_func(pred, yb, reduction='sum').item()\n","\tpred = pred.argmax(dim=1, keepdim=True)\n","\tcorrect_pred = pred.eq(yb.view_as(pred)).sum().item()\n","\treturn test_loss, correct_pred\n","\n","\n","def test(model, device, loader, loss_func, start, end, test_step_func) -> tuple[float, float, float]:\n","\tmodel.eval()\n","\ttest_loss = 0.0\n","\tcorrect_pred = 0\n","\n","\tstart.record()\n","\twith torch.no_grad():\n","\t\tfor xb, yb in loader:\n","\t\t\txb, yb = xb.to(device), yb.to(device)\n","\t\t\ttloss, cpred = test_step_func(model, xb, yb, loss_func)\n","\t\t\ttest_loss += tloss\n","\t\t\tcorrect_pred += cpred\n","\tend.record()\n","\ttorch.cuda.synchronize()\n","\n","\ttest_loss /= len(loader.dataset)\n","\tcorrect_pred /= len(loader.dataset)\n","\telapsed_time = start.elapsed_time(end)\n","\n","\treturn test_loss, correct_pred, elapsed_time\n","\n","\n","class FullyConnectedNet(nn.Module):\n","\n","\tdef __init__(self, layers=[784, 800, 10]):\n","\t\tsuper(FullyConnectedNet, self).__init__()\n","\t\tself.layers = nn.ModuleList([nn.Linear(a, b) for a, b in zip(layers[:-1], layers[1:])])\n","\n","\tdef forward(self, x):\n","\t\tfor layer in self.layers[:-1]:\n","\t\t\tx = F.relu(layer(x))\n","\t\tx = self.layers[-1](x)\n","\t\treturn F.log_softmax(x, dim=1)\n","\n","\n","class SimpleConvNet(nn.Module):\n","\n","\tdef __init__(self, num_classes=10):\n","\t\tsuper().__init__()\n","\t\tself.conv1 = nn.Sequential(\n","\t\t\tnn.Conv2d(1, 16, 5, 1, 2),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.MaxPool2d(2)\n","\t\t)\n","\t\tself.conv2 = nn.Sequential(\n","\t\t\tnn.Conv2d(16, 32, 5, 1, 2),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.MaxPool2d(2),\n","\t\t)\n","\t\tself.dense = nn.Linear(32 * 7 * 7, 500)\n","\t\tself.classifier = nn.Linear(500, num_classes)\n","\n","\tdef forward(self, x):\n","\t\tx = self.conv1(x)\n","\t\tx = self.conv2(x)\n","\t\tx = torch.flatten(x, 1)\n","\t\tx = F.relu(self.dense(x))\n","\t\treturn F.log_softmax(self.classifier(x), dim=1)\n","\n","\n","def env_builder(name: str, num_classes: int, batch_size: int, test_batch_size: int):\n","\tif name == 'FullyConnectedNet':\n","\t\tmodel = FullyConnectedNet()\n","\telif name == 'SimpleConvNet':\n","\t\tmodel = SimpleConvNet()\n","\telif name == 'ResNet-50':\n","\t\tmodel = resnet50()\n","\t\tmodel.fc = nn.Linear(in_features=2048, out_features=num_classes, bias=True)\n","\telif name == 'DenseNet-121':\n","\t\tmodel = densenet121()\n","\t\tmodel.classifier = nn.Linear(in_features=1024, out_features=num_classes, bias=True)\n","\telif name == 'MobileNet-v2':\n","\t\tmodel = mobilenet_v2()\n","\t\tmodel.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n","\telif name == 'ConvNeXt-Tiny':\n","\t\tmodel = convnext_tiny()\n","\t\tmodel.classifier[2] = nn.Linear(in_features=768, out_features=num_classes, bias=True)\n","\telse:\n","\t\traise ValueError('Invalid model name')\n","\n","\tif name == 'FullyConnectedNet':\n","\t\ttrain_dl, _, test_dl = get_mnist_loaders(batch_size, test_batch_size)\n","\t\tloss_func = F.nll_loss\n","\telif name == 'SimpleConvNet':\n","\t\ttrain_dl, _, test_dl = get_mnist_loaders(batch_size, test_batch_size, flatten=False)\n","\t\tloss_func = F.nll_loss\n","\telse:\n","\t\ttrain_dl, test_dl = get_cifar10_loaders(batch_size, test_batch_size)\n","\t\tloss_func = F.cross_entropy\n","\n","\treturn model, train_dl, test_dl, loss_func\n","\n","def latency(model, sample):\n","\tstart = torch.cuda.Event(enable_timing=True)\n","\tend = torch.cuda.Event(enable_timing=True)\n","\tstart.record()\n","\t_ = model(sample)\n","\tend.record()\n","\ttorch.cuda.synchronize()\n","\treturn start.elapsed_time(end)"],"metadata":{"id":"CRzmNg1NLdFF","executionInfo":{"status":"ok","timestamp":1714085196648,"user_tz":-120,"elapsed":266,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    print('device count:', torch.cuda.device_count())\n","    device = torch.device(0)\n","    device_cap = torch.cuda.get_device_capability()\n","    print(f\"GPU {torch.cuda.get_device_name(0)} available with compatibility {device_cap}\")\n","    if device_cap not in ((7, 0), (8, 0), (9, 0)):\n","        print(\"GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU unavailable\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsMoFtKBMIgZ","executionInfo":{"status":"ok","timestamp":1714085203059,"user_tz":-120,"elapsed":216,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"c4a74997-a8f7-4bf7-c8fc-9a245f60b47c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["device count: 1\n","GPU Tesla T4 available with compatibility (7, 5)\n","GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\n"]}]},{"cell_type":"code","source":["batch_size = 96\n","test_batch_size = 128\n","epochs = 2\n","lr = 1e-2\n","momentum = 0.9\n","num_classes = 10\n","log_interval = 200\n","timestamp = time.time_ns()\n","results_eager_filepath = f'./drive/MyDrive/colab/results/pytorch-clf-eager-{timestamp}.csv'\n","results_compile_filepath = f'./drive/MyDrive/colab/results/pytorch-clf-compile-{timestamp}.csv'\n","start = torch.cuda.Event(enable_timing=True)\n","end = torch.cuda.Event(enable_timing=True)\n","# clfs = ['FullyConnectedNet', 'SimpleConvNet', 'ResNet-50', 'DenseNet-121', 'MobileNet-v2', 'ConvNeXt-Tiny']\n","clfs = ['FullyConnectedNet', 'ConvNeXt-Tiny']"],"metadata":{"id":"jeaDjRnmoo-9","executionInfo":{"status":"ok","timestamp":1714085205001,"user_tz":-120,"elapsed":235,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Training - eager mode"],"metadata":{"id":"xYX4Jfusmsvl"}},{"cell_type":"code","source":["telemetry_eager = defaultdict(list)\n","\n","# train all models - no comp\n","for model_name in clfs:\n","  print(f'Eager benchmarks for {model_name} begin')\n","\n","  model, train_dl, test_dl, loss_func = env_builder(model_name, num_classes, batch_size, test_batch_size)\n","  model = model.to(device)\n","  opt = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","\n","  for epoch in range(1, epochs + 1):\n","    running_loss = 0.0\n","    start.record()\n","    for xb, yb in train_dl:\n","      xb, yb = xb.to(device), yb.to(device)\n","      running_loss += fit_step(model, xb, yb, loss_func, opt)\n","    end.record()\n","    torch.cuda.synchronize()\n","\n","    telemetry_eager['model_name'].append(model_name)\n","    telemetry_eager['phase'].append('training')\n","    telemetry_eager['epoch'].append(epoch)\n","    telemetry_eager['loss'].append(running_loss / len(train_dl))\n","    telemetry_eager['performance'].append(-1)\n","    telemetry_eager['elapsed_time'].append(start.elapsed_time(end) * 1e6)\n","    pd.DataFrame(telemetry_eager).to_csv(results_eager_filepath, index=False)\n","    print(f'Epoch {epoch} finished with execution time of {start.elapsed_time(end) / 1e3}s')"],"metadata":{"id":"DFBxGlF2YM9q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714083332609,"user_tz":-120,"elapsed":103341,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"39e60f33-66f6-4cbe-ef97-7b316d6a7eee"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Eager benchmarks for FullyConnectedNet begin\n","Epoch 1 finished with execution time of 1.964793212890625s\n","Epoch 2 finished with execution time of 1.7931392822265626s\n","Eager benchmarks for ConvNeXt-Tiny begin\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 finished with execution time of 37.22212890625s\n","Epoch 2 finished with execution time of 38.20326953125s\n"]}]},{"cell_type":"code","source":["from pathlib import Path\n","Path('./drive/MyDrive/colab/datasets/celeba_tiny').absolute()\n","next(iter(Path('./drive/MyDrive/colab/datasets/celeba_tiny').glob('*')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0VbMOVp3U5G6","executionInfo":{"status":"ok","timestamp":1714085360525,"user_tz":-120,"elapsed":240,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"b21eca92-efd8-455c-9e1d-04b04dfb67b2"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('drive/MyDrive/colab/datasets/celeba_tiny/img_align_celeba')"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Latency - both modes"],"metadata":{"id":"mvnfRfFLrRFj"}},{"cell_type":"code","source":["# setup for compile training but its needed for saving latency results too\n","telemetry_compile = defaultdict(list)\n","# telemetry_eager = defaultdict(list) # do usuniecia !!!!!!!!!!!!!\n","\n","telemetry_compile_by_model = []"],"metadata":{"id":"aGpkD5GCSku7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k in telemetry_eager.keys():\n","  print(k, len(telemetry_eager[k]), telemetry_eager[k])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Erf9mZeN0VqS","executionInfo":{"status":"ok","timestamp":1711400946128,"user_tz":-60,"elapsed":10,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"38428bcc-12b1-4c59-ff35-b29096b926af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model_name 4 ['FullyConnectedNet', 'FullyConnectedNet', 'ConvNeXt-Tiny', 'ConvNeXt-Tiny']\n","phase 4 ['training', 'training', 'training', 'training']\n","epoch 4 [1, 2, 1, 2]\n","loss 4 [0.5556255227088929, 0.31790154234170914, 1.8624580731758704, 1.7259240872584856]\n","performance 4 [-1, -1, -1, -1]\n","elapsed_time 4 [2318406738.28125, 3975225585.9375, 33795152343.75, 33870371093.75]\n"]}]},{"cell_type":"code","source":["for model_name in clfs:\n","  telemetry_eager_times = []\n","  telemetry_compile_times = []\n","\n","  # prepare models\n","  model, _, test_dl, _ = env_builder(model_name, num_classes, batch_size, test_batch_size)\n","  model = model.to(device)\n","  torch._dynamo.reset()\n","  model_comp = torch.compile(model, mode='reduce-overhead')\n","  # model, model_comp = model.to(device), model_comp.to(device)\n","\n","  # prepare samples\n","  batch = next(iter(test_dl))\n","  batch = batch[0].to(device)\n","  sample = batch[0].unsqueeze(dim=0)\n","\n","  # measure compilation time\n","  with torch.no_grad():\n","    e = latency(model, sample)\n","    print('compilation - eager mode:', e)\n","    telemetry_eager_times.append(e)\n","\n","    c = latency(model_comp, sample)\n","    print('compilation - compile mode:', c)\n","    telemetry_compile_times.append(c)\n","\n","    # measure latency (with warm-up runs in case of recompilation)\n","    for i in range(epochs + 10):\n","      sample = batch[i].unsqueeze(dim=0)\n","\n","      e = latency(model, sample)\n","      c = latency(model_comp, sample)\n","\n","      if i >= 10:\n","        telemetry_eager_times.append(e)\n","        telemetry_compile_times.append(c)\n","\n","    em = np.median(telemetry_eager_times)\n","    cm = np.median(telemetry_compile_times)\n","    print(f'median exec time (e/c): {em} / {cm}')\n","    print(f'compiled graph is on average {em / cm} times faster than eager execution')\n","\n","  # after completing latency benchmarks, save gathered telemetry\n","  # lists -> aggregated list -> append to dicts\n","\n","  telemetry_compile_by_model.append((model_name, telemetry_eager_times, telemetry_compile_times))"],"metadata":{"id":"bC5IQFaXsqCV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711401104912,"user_tz":-60,"elapsed":19608,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"outputId":"9a78cf1f-5a05-4686-c610-c1f7b55c2f41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["compilation - eager mode: 0.6730560064315796\n","compilation - compile mode: 684.1569213867188\n","median exec time (e/c): 0.36003199219703674 / 0.3521920144557953\n","compiled graph is on average 1.0222605210210565 times faster than eager execution\n","Files already downloaded and verified\n","Files already downloaded and verified\n","compilation - eager mode: 23.43926429748535\n","compilation - compile mode: 11417.072265625\n","median exec time (e/c): 6.752992153167725 / 2.512576103210449\n","compiled graph is on average 2.6876766616299004 times faster than eager execution\n"]}]},{"cell_type":"code","source":["for model_name, telemetry_eager_times, telemetry_compile_times in telemetry_compile_by_model:\n","\n","  for telemetry, telemetry_times, results_filepath in [\n","      (telemetry_eager, telemetry_eager_times, results_eager_filepath),\n","      (telemetry_compile, telemetry_compile_times, results_compile_filepath)\n","    ]:\n","    telemetry['model_name'].append(model_name)\n","    telemetry['phase'].append('graph_compilation')\n","    telemetry['epoch'].append(1)\n","    telemetry['loss'].append(-1)\n","    telemetry['performance'].append(-1)\n","    telemetry['elapsed_time'].append(telemetry_times[0])\n","\n","    telemetry['model_name'].extend([model_name] * epochs)\n","    telemetry['phase'].extend(['latency'] * epochs)\n","    telemetry['epoch'].extend(list(range(1, epochs + 1)))\n","    telemetry['loss'].extend([-1] * epochs)\n","    telemetry['performance'].extend([-1] * epochs)\n","    telemetry['elapsed_time'].extend(telemetry_times[1:])\n","\n","    pd.DataFrame(telemetry).to_csv(results_filepath, index=False)"],"metadata":{"id":"UxGKiF2i2UkE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Latency on batch - both modes\n","bc on single sample compile sucks apparently"],"metadata":{"id":"4J4tAcBZjxo0"}},{"cell_type":"code","source":["telemetry_compile_by_model = []"],"metadata":{"id":"FuOnTJOPb_d-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# clfs = ['FullyConnectedNet', 'SimpleConvNet', 'ResNet-50', 'DenseNet-121', 'MobileNet-v2', 'ConvNeXt-Tiny']\n","for model_name in clfs:\n","  telemetry_eager_times = []\n","  telemetry_compile_times = []\n","\n","  # prepare models\n","  model, _, test_dl, _ = env_builder(model_name, num_classes, batch_size, test_batch_size)\n","  model = model.to(device)\n","  torch._dynamo.reset()\n","  model_comp = torch.compile(model, mode='reduce-overhead')\n","  # model, model_comp = model.to(device), model_comp.to(device)\n","\n","  # prepare samples\n","  batch = next(iter(test_dl))\n","  batch = batch[0].to(device)\n","\n","  # measure compilation time\n","  with torch.no_grad():\n","    e = latency(model, batch)\n","    print('compilation - eager mode:', e)\n","    telemetry_eager_times.append(e)\n","\n","    c = latency(model_comp, batch)\n","    print('compilation - compile mode:', c)\n","    telemetry_compile_times.append(c)\n","\n","    # measure latency (with warm-up runs in case of recompilation)\n","    test_dl_state = iter(test_dl)\n","    for i in range(epochs + 10):\n","      batch = next(test_dl_state)\n","      batch = batch[0].to(device)\n","\n","      e = latency(model, batch)\n","      c = latency(model_comp, batch)\n","\n","      if i >= 10:\n","        telemetry_eager_times.append(e)\n","        telemetry_compile_times.append(c)\n","\n","    em = np.median(telemetry_eager_times)\n","    cm = np.median(telemetry_compile_times)\n","    print(f'median exec time (e/c): {em} / {cm}')\n","    print(f'compiled graph is on average {em / cm} times faster than eager execution')\n","\n","  # after completing latency benchmarks, save gathered telemetry\n","  # lists -> append to dicts\n","\n","telemetry_compile_by_model.append((model_name, telemetry_eager_times, telemetry_compile_times))"],"metadata":{"id":"gfNktSCImPRV","executionInfo":{"status":"ok","timestamp":1711402462337,"user_tz":-60,"elapsed":26237,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9cd4c215-0408-4221-fa08-8bcd4c2ecb8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["compilation - eager mode: 0.9705280065536499\n","compilation - compile mode: 490.14581298828125\n","median exec time (e/c): 0.4360960125923157 / 0.4285759925842285\n","compiled graph is on average 1.0175465264928698 times faster than eager execution\n","Files already downloaded and verified\n","Files already downloaded and verified\n","compilation - eager mode: 24.78780746459961\n","compilation - compile mode: 19594.263671875\n","median exec time (e/c): 36.413822174072266 / 8.255359649658203\n","compiled graph is on average 4.410931045939338 times faster than eager execution\n"]}]},{"cell_type":"code","source":["for model_name, telemetry_eager_times, telemetry_compile_times in telemetry_compile_by_model:\n","\n","  for telemetry, telemetry_times, results_filepath in [\n","      (telemetry_eager, telemetry_eager_times, results_eager_filepath),\n","      (telemetry_compile, telemetry_compile_times, results_compile_filepath)\n","    ]:\n","    telemetry['model_name'].append(model_name)\n","    telemetry['phase'].append('graph_compilation_batch')\n","    telemetry['epoch'].append(1)\n","    telemetry['loss'].append(-1)\n","    telemetry['performance'].append(-1)\n","    telemetry['elapsed_time'].append(telemetry_times[0])\n","\n","    telemetry['model_name'].extend([model_name] * epochs)\n","    telemetry['phase'].extend(['latency_batch'] * epochs)\n","    telemetry['epoch'].extend(list(range(1, epochs + 1)))\n","    telemetry['loss'].extend([-1] * epochs)\n","    telemetry['performance'].extend([-1] * epochs)\n","    telemetry['elapsed_time'].extend(telemetry_times[1:])\n","\n","    pd.DataFrame(telemetry).to_csv(results_filepath, index=False)"],"metadata":{"id":"9V4LcCnibyOU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training - compile mode\n","with some special setup since it's rather unstable"],"metadata":{"id":"d2iy1vzjm5bg"}},{"cell_type":"code","source":["telemetry_compile_by_model = []"],"metadata":{"id":"tGHdYViYjZHu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# clfs = ['FullyConnectedNet', 'SimpleConvNet', 'ResNet-50', 'DenseNet-121', 'MobileNet-v2', 'ConvNeXt-Tiny']\n","model_name = clfs[1]"],"metadata":{"id":"N2UMjfvXnLWM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tc_part = defaultdict(list)\n","\n","# train all models - compiled nets and funcs\n","print(f'Compiled benchmarks for {model_name} begin')\n","\n","model, train_dl, test_dl, loss_func = env_builder(model_name, num_classes, batch_size, test_batch_size)\n","model = model.to(device)\n","torch._dynamo.reset()\n","model = torch.compile(model, mode='reduce-overhead')\n","opt = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","fit_step_compiled = torch.compile(fit_step, mode=\"reduce-overhead\")\n","\n","for epoch in range(1, epochs + 1):\n","  running_loss = 0.0\n","  start.record()\n","  for xb, yb in train_dl:\n","    xb, yb = xb.to(device), yb.to(device)\n","    running_loss += fit_step_compiled(model, xb, yb, loss_func, opt)\n","  end.record()\n","  torch.cuda.synchronize()\n","\n","  tc_part['model_name'].append(model_name)\n","  tc_part['phase'].append('training')\n","  tc_part['epoch'].append(epoch)\n","  tc_part['loss'].append(running_loss / len(train_dl))\n","  tc_part['performance'].append(-1)\n","  tc_part['elapsed_time'].append(start.elapsed_time(end) * 1e6)\n","  print(f'Epoch {epoch} finished with execution time of {start.elapsed_time(end) / 1e3}s')\n","  telemetry_compile_by_model.append(tc_part)"],"metadata":{"id":"gMEnf8iSEAh0","executionInfo":{"status":"ok","timestamp":1711402897816,"user_tz":-60,"elapsed":98147,"user":{"displayName":"Michał Banaszczak","userId":"07446547104495388771"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c90a4408-a6b4-41e8-a0fb-f8168998acb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Compiled benchmarks for ConvNeXt-Tiny begin\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch 1 finished with execution time of 66.1982421875s\n","Epoch 2 finished with execution time of 28.592625s\n"]}]},{"cell_type":"code","source":["def reduce_telemetry_dicts(agg_t, update_t):\n","\tfor key in update_t.keys():\n","\t\tagg_t[key].extend(update_t[key])\n","\treturn agg_t\n","\n","telemetry_compile_full = reduce(reduce_telemetry_dicts, telemetry_compile_by_model, telemetry_compile)\n","\n","pd.DataFrame(telemetry_compile_full).to_csv(results_compile_filepath, index=False)"],"metadata":{"id":"jppCBixYlEPy"},"execution_count":null,"outputs":[]}]}