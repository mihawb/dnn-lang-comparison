{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fb24b584610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from ultralytics import YOLO\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Resize, Compose\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device count: 1\n",
      "GPU NVIDIA GeForce GTX 1050 available with compatibility (6, 1)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\tprint('device count:', torch.cuda.device_count())\n",
    "\tdevice = torch.device(0)\n",
    "\tdevice_cap = torch.cuda.get_device_capability()\n",
    "\tprint(f\"GPU {torch.cuda.get_device_name(0)} available with compatibility {device_cap}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU unavailable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coco2017Dataset(Dataset):\n",
    "  def __init__(self, img_dir: str, transform=None) -> None:\n",
    "    assert (p := Path(img_dir)).exists() and p.is_dir(), f\"Image directory {img_dir} does not exist\"\n",
    "    self.img_paths = [str(p) for p in Path(img_dir).glob(\"*.jpg\")]\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.img_paths)\n",
    "\n",
    "  def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "    img_path = self.img_paths[idx]\n",
    "    img = read_image(img_path)\n",
    "    if self.transform:\n",
    "        img = self.transform(img / 255).to(torch.float32)\n",
    "    return img\n",
    "\n",
    "\n",
    "class Expand(object):\n",
    "  def __call__(self, sample: torch.Tensor) -> torch.Tensor:\n",
    "    if sample.size()[0] != 3:\n",
    "      deep_copy = sample.detach().clone()\n",
    "      return deep_copy.expand(3, -1, -1)\n",
    "    else:\n",
    "      return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1738789097930510070\n"
     ]
    }
   ],
   "source": [
    "coco_ds = Coco2017Dataset(\n",
    "  img_dir=\"../../datasets/coco2017_val\",\n",
    "  transform=Compose([\n",
    "      Resize(size=(640, 640), antialias=True),\n",
    "      Expand()\n",
    "  ])\n",
    ")\n",
    "# plt.imshow(coco_ds[0].permute(1, 2, 0))\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "timestamp = time.time_ns()\n",
    "print(timestamp)\n",
    "results_filepath = f'../../results_ultimate_0/pytorch-yolo-{timestamp}.csv'\n",
    "telemetry = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Benchmark: 100%|██████████| 5000/5000 [07:02<00:00, 11.83it/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8m.pt\", verbose=False).to(device)\n",
    "assert model.device.type == \"cuda\"\n",
    "\n",
    "# 5k warmup\n",
    "# for img in tqdm(coco_ds, desc=\"Warmup\"):\n",
    "#   img = img.unsqueeze(dim=0).to(device)\n",
    "#   _ = model.predict(img, device=device)\n",
    "# with 5k images warmup not necessary on second thought\n",
    "\n",
    "# latency benchmark\n",
    "for i, img in enumerate(tqdm(coco_ds, desc=\"Benchmark\"), start=1):\n",
    "  img = img.unsqueeze(dim=0).to(device)\n",
    "\n",
    "  start.record()\n",
    "  res = model.predict(img, device=device, verbose=False)\n",
    "  end.record()\n",
    "  torch.cuda.synchronize()\n",
    "\n",
    "  telemetry[\"framework\"].append(\"PyTorch\")\n",
    "  telemetry[\"model_name\"].append(\"YOLOv8m\")\n",
    "  telemetry[\"phase\"].append(\"latency\")\n",
    "  telemetry[\"epoch\"].append(i)\n",
    "  telemetry[\"loss\"].append(-1)\n",
    "  telemetry[\"performance\"].append(start.elapsed_time(end))  # idk who cares how much those times differ but i wanna see\n",
    "  telemetry[\"elapsed_time\"].append(res[0].speed[\"inference\"])\n",
    "pd.DataFrame(telemetry).to_csv(results_filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
